{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804e8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970288d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "# https://research.unsw.edu.au/projects/unsw-nb15-dataset\n",
    "# According to the website above csv is wrongly saved, so I change the name\n",
    "# The number of records in the training set is 175,341 records and the testing set is 82,332 records from the different types, attack and normal.\n",
    "df = pd.read_csv('../../Data/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d76a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "# Pytorch\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8caeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>attack_cat_Analysis</th>\n",
       "      <th>attack_cat_Backdoor</th>\n",
       "      <th>attack_cat_DoS</th>\n",
       "      <th>attack_cat_Exploits</th>\n",
       "      <th>attack_cat_Fuzzers</th>\n",
       "      <th>attack_cat_Generic</th>\n",
       "      <th>attack_cat_Normal</th>\n",
       "      <th>attack_cat_Reconnaissance</th>\n",
       "      <th>attack_cat_Shellcode</th>\n",
       "      <th>attack_cat_Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>39.417980</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.637109</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>26.683033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.521584</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>32.593026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.542905</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>31.313031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.258687</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>57.985135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.121478    113        0      2      6      4     258     172   \n",
       "1   2  0.649902    113        0      2     14     38     734   42014   \n",
       "2   3  1.623129    113        0      2      8     16     364   13186   \n",
       "3   4  1.681642    113        3      2     12     12     628     770   \n",
       "4   5  0.449454    113        0      2     10      6     534     268   \n",
       "5   6  0.380537    113        0      2     10      6     534     268   \n",
       "6   7  0.637109    113        0      2     10      8     534     354   \n",
       "7   8  0.521584    113        0      2     10      8     534     354   \n",
       "8   9  0.542905    113        0      2     10      8     534     354   \n",
       "9  10  0.258687    113        0      2     10      6     534     268   \n",
       "\n",
       "        rate  ...  attack_cat_Analysis  attack_cat_Backdoor  attack_cat_DoS  \\\n",
       "0  74.087490  ...                    0                    0               0   \n",
       "1  78.473372  ...                    0                    0               0   \n",
       "2  14.170161  ...                    0                    0               0   \n",
       "3  13.677108  ...                    0                    0               0   \n",
       "4  33.373826  ...                    0                    0               0   \n",
       "5  39.417980  ...                    0                    0               0   \n",
       "6  26.683033  ...                    0                    0               0   \n",
       "7  32.593026  ...                    0                    0               0   \n",
       "8  31.313031  ...                    0                    0               0   \n",
       "9  57.985135  ...                    0                    0               0   \n",
       "\n",
       "   attack_cat_Exploits  attack_cat_Fuzzers  attack_cat_Generic  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   0   \n",
       "3                    0                   0                   0   \n",
       "4                    0                   0                   0   \n",
       "5                    0                   0                   0   \n",
       "6                    0                   0                   0   \n",
       "7                    0                   0                   0   \n",
       "8                    0                   0                   0   \n",
       "9                    0                   0                   0   \n",
       "\n",
       "   attack_cat_Normal  attack_cat_Reconnaissance  attack_cat_Shellcode  \\\n",
       "0                  1                          0                     0   \n",
       "1                  1                          0                     0   \n",
       "2                  1                          0                     0   \n",
       "3                  1                          0                     0   \n",
       "4                  1                          0                     0   \n",
       "5                  1                          0                     0   \n",
       "6                  1                          0                     0   \n",
       "7                  1                          0                     0   \n",
       "8                  1                          0                     0   \n",
       "9                  1                          0                     0   \n",
       "\n",
       "   attack_cat_Worms  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nominal to numeric of data\n",
    "# proto                 object\n",
    "# service               object\n",
    "# state                 object\n",
    "\n",
    "# proto to numeric\n",
    "# proto_mapping = {'xxx':2, 'xxx':1, 'xxx':0}\n",
    "# data['proto'] = data['proto'].map(proto_mapping)\n",
    "\n",
    "# proto to numeric\n",
    "proto_le = LabelEncoder()\n",
    "df['proto'] = proto_le.fit_transform(df['proto'])\n",
    " \n",
    "# service to numeric\n",
    "service_le = LabelEncoder()\n",
    "df['service'] = service_le.fit_transform(df['service'])\n",
    "\n",
    "# state to numeric\n",
    "state_le = LabelEncoder()\n",
    "df['state'] = state_le.fit_transform(df['state'])\n",
    "\n",
    "# nominal to numeric of data\n",
    "# attack_cat            object\n",
    "\n",
    "# target to numeric\n",
    "df['attack_cat2']=df['attack_cat']\n",
    "attack_cat2_le = LabelEncoder()\n",
    "df['attack_cat2'] = attack_cat2_le.fit_transform(df['attack_cat2'])\n",
    "df_processed = pd.get_dummies(df, columns=(['attack_cat']))\n",
    "\n",
    "\n",
    "df_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9edf98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_processed, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1867627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122738, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train.dtypes\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d3234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>attack_cat_Analysis</th>\n",
       "      <th>attack_cat_Backdoor</th>\n",
       "      <th>attack_cat_DoS</th>\n",
       "      <th>attack_cat_Exploits</th>\n",
       "      <th>attack_cat_Fuzzers</th>\n",
       "      <th>attack_cat_Generic</th>\n",
       "      <th>attack_cat_Normal</th>\n",
       "      <th>attack_cat_Reconnaissance</th>\n",
       "      <th>attack_cat_Shellcode</th>\n",
       "      <th>attack_cat_Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41479</th>\n",
       "      <td>41480</td>\n",
       "      <td>0.581798</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>2.578214e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174119</th>\n",
       "      <td>174120</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39585</th>\n",
       "      <td>39586</td>\n",
       "      <td>0.294033</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>424</td>\n",
       "      <td>8824</td>\n",
       "      <td>6.461860e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23269</th>\n",
       "      <td>23270</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>2.832861e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35227</th>\n",
       "      <td>35228</td>\n",
       "      <td>1.433471</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>7.324878e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157804</th>\n",
       "      <td>157805</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170646</th>\n",
       "      <td>170647</td>\n",
       "      <td>1.434152</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>450</td>\n",
       "      <td>782</td>\n",
       "      <td>1.185370e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102714</th>\n",
       "      <td>102715</td>\n",
       "      <td>1.725872</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>798</td>\n",
       "      <td>1730</td>\n",
       "      <td>1.100893e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138365</th>\n",
       "      <td>138366</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>7841</td>\n",
       "      <td>0.528823</td>\n",
       "      <td>113</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>37372</td>\n",
       "      <td>3380</td>\n",
       "      <td>1.758622e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "41479    41480  0.581798    113        0      2     10      6     588     268   \n",
       "174119  174120  0.000009    119        2      3      2      0     114       0   \n",
       "39585    39586  0.294033    113        4      2      8     12     424    8824   \n",
       "23269    23270  0.001059    119        2      0      2      2     146     178   \n",
       "35227    35228  1.433471    113        3      2     52     54    2934    3742   \n",
       "157804  157805  0.000003    119        2      3      2      0     114       0   \n",
       "170646  170647  1.434152    113        4      2     10      8     450     782   \n",
       "102714  102715  1.725872    113        5      2     10     10     798    1730   \n",
       "138365  138366  0.000001    119        2      3      2      0     114       0   \n",
       "7840      7841  0.528823    113        9      2     52     42   37372    3380   \n",
       "\n",
       "                rate  ...  attack_cat_Analysis  attack_cat_Backdoor  \\\n",
       "41479   2.578214e+01  ...                    0                    0   \n",
       "174119  1.111111e+05  ...                    0                    0   \n",
       "39585   6.461860e+01  ...                    0                    0   \n",
       "23269   2.832861e+03  ...                    0                    0   \n",
       "35227   7.324878e+01  ...                    0                    0   \n",
       "157804  3.333333e+05  ...                    0                    0   \n",
       "170646  1.185370e+01  ...                    0                    0   \n",
       "102714  1.100893e+01  ...                    0                    0   \n",
       "138365  1.000000e+06  ...                    0                    0   \n",
       "7840    1.758622e+02  ...                    0                    0   \n",
       "\n",
       "        attack_cat_DoS  attack_cat_Exploits  attack_cat_Fuzzers  \\\n",
       "41479                0                    0                   0   \n",
       "174119               0                    0                   0   \n",
       "39585                0                    0                   0   \n",
       "23269                0                    0                   0   \n",
       "35227                0                    0                   0   \n",
       "157804               0                    0                   0   \n",
       "170646               0                    1                   0   \n",
       "102714               1                    0                   0   \n",
       "138365               0                    0                   0   \n",
       "7840                 0                    0                   0   \n",
       "\n",
       "        attack_cat_Generic  attack_cat_Normal  attack_cat_Reconnaissance  \\\n",
       "41479                    0                  1                          0   \n",
       "174119                   1                  0                          0   \n",
       "39585                    0                  1                          0   \n",
       "23269                    0                  1                          0   \n",
       "35227                    0                  1                          0   \n",
       "157804                   1                  0                          0   \n",
       "170646                   0                  0                          0   \n",
       "102714                   0                  0                          0   \n",
       "138365                   1                  0                          0   \n",
       "7840                     0                  1                          0   \n",
       "\n",
       "        attack_cat_Shellcode  attack_cat_Worms  \n",
       "41479                      0                 0  \n",
       "174119                     0                 0  \n",
       "39585                      0                 0  \n",
       "23269                      0                 0  \n",
       "35227                      0                 0  \n",
       "157804                     0                 0  \n",
       "170646                     0                 0  \n",
       "102714                     0                 0  \n",
       "138365                     0                 0  \n",
       "7840                       0                 0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d9dad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41479</th>\n",
       "      <td>0.581798</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>2.578214e+01</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174119</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39585</th>\n",
       "      <td>0.294033</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>424</td>\n",
       "      <td>8824</td>\n",
       "      <td>6.461860e+01</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23269</th>\n",
       "      <td>0.001059</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>2.832861e+03</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35227</th>\n",
       "      <td>1.433471</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>7.324878e+01</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157804</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e+05</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170646</th>\n",
       "      <td>1.434152</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>450</td>\n",
       "      <td>782</td>\n",
       "      <td>1.185370e+01</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102714</th>\n",
       "      <td>1.725872</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>798</td>\n",
       "      <td>1730</td>\n",
       "      <td>1.100893e+01</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138365</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>0.528823</td>\n",
       "      <td>113</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>37372</td>\n",
       "      <td>3380</td>\n",
       "      <td>1.758622e+02</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "41479   0.581798    113        0      2     10      6     588     268   \n",
       "174119  0.000009    119        2      3      2      0     114       0   \n",
       "39585   0.294033    113        4      2      8     12     424    8824   \n",
       "23269   0.001059    119        2      0      2      2     146     178   \n",
       "35227   1.433471    113        3      2     52     54    2934    3742   \n",
       "157804  0.000003    119        2      3      2      0     114       0   \n",
       "170646  1.434152    113        4      2     10      8     450     782   \n",
       "102714  1.725872    113        5      2     10     10     798    1730   \n",
       "138365  0.000001    119        2      3      2      0     114       0   \n",
       "7840    0.528823    113        9      2     52     42   37372    3380   \n",
       "\n",
       "                rate  sttl  ...  ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "41479   2.578214e+01   254  ...           2                 1   \n",
       "174119  1.111111e+05   254  ...          15                15   \n",
       "39585   6.461860e+01    31  ...          11                 1   \n",
       "23269   2.832861e+03    31  ...           2                 1   \n",
       "35227   7.324878e+01    31  ...           4                 1   \n",
       "157804  3.333333e+05   254  ...          12                12   \n",
       "170646  1.185370e+01    62  ...           2                 1   \n",
       "102714  1.100893e+01    62  ...           1                 1   \n",
       "138365  1.000000e+06   254  ...          16                16   \n",
       "7840    1.758622e+02    31  ...           2                 1   \n",
       "\n",
       "        ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "41479                  1               1             0           0   \n",
       "174119                15              31             0           0   \n",
       "39585                  1               5             0           0   \n",
       "23269                  1               1             0           0   \n",
       "35227                  1               5             1           1   \n",
       "157804                12              14             0           0   \n",
       "170646                 1               2             0           0   \n",
       "102714                 1               1             0           0   \n",
       "138365                16              18             0           0   \n",
       "7840                   1               3             0           0   \n",
       "\n",
       "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "41479                  0           1           5                0  \n",
       "174119                 0          15          31                0  \n",
       "39585                  0           3           6                0  \n",
       "23269                  0           4           2                0  \n",
       "35227                  0           6           2                0  \n",
       "157804                 0          12          14                0  \n",
       "170646                 0           4           1                0  \n",
       "102714                 1           1           1                0  \n",
       "138365                 0          16          18                0  \n",
       "7840                   0           4           1                0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = df_train.drop(['id', 'label', 'attack_cat2','attack_cat_Analysis','attack_cat_Backdoor','attack_cat_DoS','attack_cat_Exploits','attack_cat_Fuzzers','attack_cat_Generic','attack_cat_Normal','attack_cat_Reconnaissance','attack_cat_Shellcode','attack_cat_Worms'], axis=1)\n",
    "analysis_train = df_train.iloc[:,-10]\n",
    "backdoor_train = df_train.iloc[:,-9]\n",
    "dos_train = df_train.iloc[:,-8]\n",
    "exploits_train = df_train.iloc[:,-7]\n",
    "fuzzers_train = df_train.iloc[:,-6]\n",
    "generic_train = df_train.iloc[:,-5]\n",
    "normal_train = df_train.iloc[:,-4]\n",
    "reconnaissance_train = df_train.iloc[:,-3]\n",
    "shellcode_train = df_train.iloc[:,-2]\n",
    "worms_train = df_train.iloc[:,-1]\n",
    "\n",
    "attack_train = df_train.iloc[:,-11]\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f8a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max scaling\n",
    "data_train_norm = (data_train - data_train.min()) / (data_train.max() - data_train.min())\n",
    "data_train_norm = data_train_norm.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653d050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41479</th>\n",
       "      <td>9.696635e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174119</th>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39585</th>\n",
       "      <td>4.900551e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23269</th>\n",
       "      <td>1.765000e-05</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35227</th>\n",
       "      <td>2.389119e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157804</th>\n",
       "      <td>5.000001e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170646</th>\n",
       "      <td>2.390254e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102714</th>\n",
       "      <td>2.876454e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138365</th>\n",
       "      <td>1.666667e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>8.813718e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dur     proto   service     state     spkts     dpkts  \\\n",
       "41479   9.696635e-03  0.856061  0.000000  0.285714  0.000936  0.000553   \n",
       "174119  1.500000e-07  0.901515  0.166667  0.428571  0.000104  0.000000   \n",
       "39585   4.900551e-03  0.856061  0.333333  0.285714  0.000728  0.001106   \n",
       "23269   1.765000e-05  0.901515  0.166667  0.000000  0.000104  0.000184   \n",
       "35227   2.389119e-02  0.856061  0.250000  0.285714  0.005304  0.004977   \n",
       "157804  5.000001e-08  0.901515  0.166667  0.428571  0.000104  0.000000   \n",
       "170646  2.390254e-02  0.856061  0.333333  0.285714  0.000936  0.000737   \n",
       "102714  2.876454e-02  0.856061  0.416667  0.285714  0.000936  0.000922   \n",
       "138365  1.666667e-08  0.901515  0.166667  0.428571  0.000104  0.000000   \n",
       "7840    8.813718e-03  0.856061  0.750000  0.285714  0.005304  0.003871   \n",
       "\n",
       "          sbytes    dbytes      rate      sttl  ...  ct_dst_ltm  \\\n",
       "41479   0.000042  0.000018  0.000026  0.996078  ...        0.02   \n",
       "174119  0.000005  0.000000  0.111111  0.996078  ...        0.28   \n",
       "39585   0.000029  0.000609  0.000065  0.121569  ...        0.20   \n",
       "23269   0.000008  0.000012  0.002833  0.121569  ...        0.02   \n",
       "35227   0.000223  0.000258  0.000073  0.121569  ...        0.06   \n",
       "157804  0.000005  0.000000  0.333333  0.996078  ...        0.22   \n",
       "170646  0.000031  0.000054  0.000012  0.243137  ...        0.02   \n",
       "102714  0.000058  0.000119  0.000011  0.243137  ...        0.00   \n",
       "138365  0.000005  0.000000  1.000000  0.996078  ...        0.30   \n",
       "7840    0.002879  0.000233  0.000176  0.121569  ...        0.02   \n",
       "\n",
       "        ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "41479               0.00          0.000000        0.000000          0.00   \n",
       "174119              0.28          0.311111        0.483871          0.00   \n",
       "39585               0.00          0.000000        0.064516          0.00   \n",
       "23269               0.00          0.000000        0.000000          0.00   \n",
       "35227               0.00          0.000000        0.064516          0.25   \n",
       "157804              0.22          0.244444        0.209677          0.00   \n",
       "170646              0.00          0.000000        0.016129          0.00   \n",
       "102714              0.00          0.000000        0.000000          0.00   \n",
       "138365              0.30          0.333333        0.274194          0.00   \n",
       "7840                0.00          0.000000        0.032258          0.00   \n",
       "\n",
       "        ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "41479         0.00          0.000000    0.000000    0.065574              0.0  \n",
       "174119        0.00          0.000000    0.237288    0.491803              0.0  \n",
       "39585         0.00          0.000000    0.033898    0.081967              0.0  \n",
       "23269         0.00          0.000000    0.050847    0.016393              0.0  \n",
       "35227         0.25          0.000000    0.084746    0.016393              0.0  \n",
       "157804        0.00          0.000000    0.186441    0.213115              0.0  \n",
       "170646        0.00          0.000000    0.050847    0.000000              0.0  \n",
       "102714        0.00          0.033333    0.000000    0.000000              0.0  \n",
       "138365        0.00          0.000000    0.254237    0.278689              0.0  \n",
       "7840          0.00          0.000000    0.050847    0.000000              0.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_norm.shape\n",
    "data_train_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd5a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing 10 types of binary classification set\n",
    "train_X = torch.tensor(data_train_norm.values, dtype=torch.float32)\n",
    "\n",
    "train_analysis_Y = torch.tensor(analysis_train.values, dtype=torch.long) \n",
    "train_backdoor_Y = torch.tensor(backdoor_train.values, dtype=torch.long) \n",
    "train_dos_Y = torch.tensor(dos_train.values, dtype=torch.long) \n",
    "train_exploits_Y = torch.tensor(exploits_train.values, dtype=torch.long) \n",
    "train_fuzzers_Y = torch.tensor(fuzzers_train.values, dtype=torch.long) \n",
    "train_generic_Y = torch.tensor(generic_train.values, dtype=torch.long) \n",
    "train_normal_Y = torch.tensor(normal_train.values, dtype=torch.long) \n",
    "train_reconnaissance_Y = torch.tensor(reconnaissance_train.values, dtype=torch.long) \n",
    "train_shellcode_Y = torch.tensor(shellcode_train.values, dtype=torch.long) \n",
    "train_worms_Y = torch.tensor(worms_train.values, dtype=torch.long) \n",
    "\n",
    "train_analysis = TensorDataset(train_X, train_analysis_Y)\n",
    "train_backdoor = TensorDataset(train_X, train_backdoor_Y)\n",
    "train_dos = TensorDataset(train_X, train_dos_Y)\n",
    "train_exploits = TensorDataset(train_X, train_exploits_Y)\n",
    "train_fuzzers = TensorDataset(train_X, train_fuzzers_Y)\n",
    "train_generic = TensorDataset(train_X, train_generic_Y)\n",
    "train_normal = TensorDataset(train_X, train_normal_Y)\n",
    "train_reconnaissance = TensorDataset(train_X, train_reconnaissance_Y)\n",
    "train_shellcode = TensorDataset(train_X, train_shellcode_Y)\n",
    "train_worms = TensorDataset(train_X, train_worms_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed42e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analysis_loader = DataLoader(train_analysis, batch_size=100, shuffle=True)\n",
    "train_backdoor_loader = DataLoader(train_backdoor, batch_size=100, shuffle=True)\n",
    "train_dos_loader = DataLoader(train_dos, batch_size=100, shuffle=True)\n",
    "train_exploits_loader = DataLoader(train_exploits, batch_size=100, shuffle=True)\n",
    "train_fuzzers_loader = DataLoader(train_fuzzers, batch_size=100, shuffle=True)\n",
    "train_generic_loader = DataLoader(train_generic, batch_size=100, shuffle=True)\n",
    "train_normal_loader = DataLoader(train_normal, batch_size=100, shuffle=True)\n",
    "train_reconnaissance_loader = DataLoader(train_reconnaissance, batch_size=100, shuffle=True)\n",
    "train_shellcode_loader = DataLoader(train_shellcode, batch_size=100, shuffle=True)\n",
    "train_worms_loader = DataLoader(train_worms, batch_size=100, shuffle=True)\n",
    "# drop_last = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06bdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 2)\n",
    "        self.bc1 = nn.BatchNorm1d(100)\n",
    "        self.bc2 = nn.BatchNorm1d(100)\n",
    "        self.bc3 = nn.BatchNorm1d(100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bc1(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bc2(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bc3(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model_analysis = Net()\n",
    "model_backdoor = Net()\n",
    "model_dos = Net()\n",
    "model_exploits = Net()\n",
    "model_fuzzers = Net()\n",
    "model_generic = Net()\n",
    "model_normal = Net()\n",
    "model_reconnaissance = Net()\n",
    "model_shellcode = Net()\n",
    "model_worms = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715a1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96aed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_analysis = model_analysis.to(device)\n",
    "model_backdoor = model_backdoor.to(device)\n",
    "model_dos = model_dos.to(device)\n",
    "model_exploits = model_exploits.to(device)\n",
    "model_fuzzers = model_fuzzers.to(device)\n",
    "model_generic = model_generic.to(device)\n",
    "model_normal = model_normal.to(device)\n",
    "model_reconnaissance = model_reconnaissance.to(device)\n",
    "model_shellcode = model_shellcode.to(device)\n",
    "model_worms = model_worms.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc76076",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd985de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.03)\n",
    "optimizer_analysis = torch.optim.Adam(model_analysis.parameters(), lr=0.03)\n",
    "optimizer_backdoor = torch.optim.Adam(model_backdoor.parameters(), lr=0.03)\n",
    "optimizer_dos = torch.optim.Adam(model_dos.parameters(), lr=0.03)\n",
    "optimizer_exploits = torch.optim.Adam(model_exploits.parameters(), lr=0.03)\n",
    "optimizer_fuzzers = torch.optim.Adam(model_fuzzers.parameters(), lr=0.03)\n",
    "optimizer_generic = torch.optim.Adam(model_generic.parameters(), lr=0.03)\n",
    "optimizer_normal = torch.optim.Adam(model_normal.parameters(), lr=0.03)\n",
    "optimizer_reconnaissance = torch.optim.Adam(model_reconnaissance.parameters(), lr=0.03)\n",
    "optimizer_shellcode = torch.optim.Adam(model_shellcode.parameters(), lr=0.03)\n",
    "optimizer_worms = torch.optim.Adam(model_worms.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5348cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the machine learning model\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_analysis.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_analysis_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_analysis.zero_grad()\n",
    "        output = model_analysis(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_analysis.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_analysis_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce234cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 121461/122738 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_analysis.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_analysis_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_analysis = model_analysis(train_x)\n",
    "    pred = torch.max(output_analysis.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63b7946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b304bd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.124398e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652119e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.162503e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.420381e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.428961e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.485195e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.902930e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred\n",
       "0   1.124398e-09\n",
       "1   1.652119e-13\n",
       "2   0.000000e+00\n",
       "3   2.162503e-31\n",
       "4   0.000000e+00\n",
       "5   3.420381e-14\n",
       "6   7.428961e-08\n",
       "7   4.485195e-02\n",
       "8   2.902930e-28\n",
       "9   0.000000e+00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data = pd.DataFrame()\n",
    "twoS_train_data[\"analysis_pred\"]=output_analysis.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd2997ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87395</th>\n",
       "      <td>1.928715e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171525</th>\n",
       "      <td>6.666668e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100997</th>\n",
       "      <td>3.536851e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106304</th>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170606</th>\n",
       "      <td>1.929705e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113031</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70458</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138025</th>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135044</th>\n",
       "      <td>1.166667e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161530</th>\n",
       "      <td>5.000001e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dur     proto   service  state     spkts     dpkts    sbytes  \\\n",
       "87395   1.928715e-02  0.856061  0.416667  0.250  0.000948  0.000729  0.000074   \n",
       "171525  6.666668e-08  0.901515  0.166667  0.375  0.000105  0.000000  0.000007   \n",
       "100997  3.536851e-03  0.856061  0.000000  0.000  0.000527  0.000182  0.000076   \n",
       "106304  1.500000e-07  0.909091  0.000000  0.375  0.000105  0.000000  0.000014   \n",
       "170606  1.929705e-02  0.856061  0.416667  0.250  0.000948  0.000729  0.000040   \n",
       "113031  1.333334e-07  0.901515  0.000000  0.375  0.000105  0.000000  0.000011   \n",
       "70458   1.333334e-07  0.022727  0.000000  0.375  0.000105  0.000000  0.000014   \n",
       "138025  1.500000e-07  0.901515  0.166667  0.375  0.000105  0.000000  0.000007   \n",
       "135044  1.166667e-07  0.901515  0.166667  0.375  0.000105  0.000000  0.000007   \n",
       "161530  5.000001e-08  0.901515  0.166667  0.375  0.000105  0.000000  0.000007   \n",
       "\n",
       "          dbytes      rate      sttl  ...  ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "87395   0.000024  0.000015  0.996078  ...        0.00              0.00   \n",
       "171525  0.000000  0.250000  0.996078  ...        0.28              0.26   \n",
       "100997  0.000006  0.000033  0.243137  ...        0.06              0.06   \n",
       "106304  0.000000  0.111111  0.996078  ...        0.04              0.04   \n",
       "170606  0.000024  0.000015  0.996078  ...        0.00              0.02   \n",
       "113031  0.000000  0.125000  0.996078  ...        0.00              0.00   \n",
       "70458   0.000000  0.125000  0.996078  ...        0.02              0.02   \n",
       "138025  0.000000  0.111111  0.996078  ...        0.54              0.52   \n",
       "135044  0.000000  0.142857  0.996078  ...        0.30              0.30   \n",
       "161530  0.000000  0.333333  0.996078  ...        0.06              0.06   \n",
       "\n",
       "        ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "87395           0.000000        0.062500           0.0         0.0   \n",
       "171525          0.288889        0.203125           0.0         0.0   \n",
       "100997          0.000000        0.093750           0.0         0.0   \n",
       "106304          0.044444        0.046875           0.0         0.0   \n",
       "170606          0.000000        0.000000           0.0         0.0   \n",
       "113031          0.000000        0.000000           0.0         0.0   \n",
       "70458           0.022222        0.031250           0.0         0.0   \n",
       "138025          0.266667        0.406250           0.0         0.0   \n",
       "135044          0.333333        0.375000           0.0         0.0   \n",
       "161530          0.066667        0.296875           0.0         0.0   \n",
       "\n",
       "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "87395           0.000000        0.00    0.000000              0.0  \n",
       "171525          0.000000        0.26    0.213115              0.0  \n",
       "100997          0.000000        0.08    0.098361              0.0  \n",
       "106304          0.000000        0.04    0.049180              0.0  \n",
       "170606          0.033333        0.36    0.000000              0.0  \n",
       "113031          0.000000        0.02    0.016393              0.0  \n",
       "70458           0.000000        0.04    0.032787              0.0  \n",
       "138025          0.000000        0.52    0.426230              0.0  \n",
       "135044          0.000000        0.32    0.393443              0.0  \n",
       "161530          0.000000        0.06    0.311475              0.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = df_test.drop(['id', 'label', 'attack_cat2','attack_cat_Analysis','attack_cat_Backdoor','attack_cat_DoS','attack_cat_Exploits','attack_cat_Fuzzers','attack_cat_Generic','attack_cat_Normal','attack_cat_Reconnaissance','attack_cat_Shellcode','attack_cat_Worms'], axis=1)\n",
    "\n",
    "analysis_test = df_test.iloc[:,-10]\n",
    "backdoor_test = df_test.iloc[:,-9]\n",
    "dos_test = df_test.iloc[:,-8]\n",
    "exploits_test = df_test.iloc[:,-7]\n",
    "fuzzers_test = df_test.iloc[:,-6]\n",
    "generic_test = df_test.iloc[:,-5]\n",
    "normal_test = df_test.iloc[:,-4]\n",
    "reconnaissance_test = df_test.iloc[:,-3]\n",
    "shellcode_test = df_test.iloc[:,-2]\n",
    "worms_test = df_test.iloc[:,-1]\n",
    "\n",
    "attack_test = df_test.iloc[:,-11]\n",
    "\n",
    "#min-max scaling\n",
    "testdata_norm = (testdata - testdata.min()) / (testdata.max() - testdata.min())\n",
    "testdata_norm = testdata_norm.fillna(0)\n",
    "\n",
    "testdata_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8613787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_X = torch.tensor(testdata_norm.values, dtype=torch.float32)\n",
    "#test_Y = torch.tensor(testlabel.values, dtype=torch.long) \n",
    "\n",
    "#test = TensorDataset(test_X, test_Y)\n",
    "#test_loader = DataLoader(test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e08eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing 10 types of binary classification set\n",
    "test_X = torch.tensor(testdata_norm.values, dtype=torch.float32)\n",
    "\n",
    "test_analysis_Y = torch.tensor(analysis_test.values, dtype=torch.long) \n",
    "test_backdoor_Y = torch.tensor(backdoor_test.values, dtype=torch.long) \n",
    "test_dos_Y = torch.tensor(dos_test.values, dtype=torch.long) \n",
    "test_exploits_Y = torch.tensor(exploits_test.values, dtype=torch.long) \n",
    "test_fuzzers_Y = torch.tensor(fuzzers_test.values, dtype=torch.long) \n",
    "test_generic_Y = torch.tensor(generic_test.values, dtype=torch.long) \n",
    "test_normal_Y = torch.tensor(normal_test.values, dtype=torch.long) \n",
    "test_reconnaissance_Y = torch.tensor(reconnaissance_test.values, dtype=torch.long) \n",
    "test_shellcode_Y = torch.tensor(shellcode_test.values, dtype=torch.long) \n",
    "test_worms_Y = torch.tensor(worms_test.values, dtype=torch.long) \n",
    "\n",
    "test_analysis = TensorDataset(test_X, test_analysis_Y)\n",
    "test_backdoor = TensorDataset(test_X, test_backdoor_Y)\n",
    "test_dos = TensorDataset(test_X, test_dos_Y)\n",
    "test_exploits = TensorDataset(test_X, test_exploits_Y)\n",
    "test_fuzzers = TensorDataset(test_X, test_fuzzers_Y)\n",
    "test_generic = TensorDataset(test_X, test_generic_Y)\n",
    "test_normal = TensorDataset(test_X, test_normal_Y)\n",
    "test_reconnaissance = TensorDataset(test_X, test_reconnaissance_Y)\n",
    "test_shellcode = TensorDataset(test_X, test_shellcode_Y)\n",
    "test_worms = TensorDataset(test_X, test_worms_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad39c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_analysis_loader = DataLoader(test_analysis, batch_size=100, shuffle=True)\n",
    "test_backdoor_loader = DataLoader(test_backdoor, batch_size=100, shuffle=True)\n",
    "test_dos_loader = DataLoader(test_dos, batch_size=100, shuffle=True)\n",
    "test_exploits_loader = DataLoader(test_exploits, batch_size=100, shuffle=True)\n",
    "test_fuzzers_loader = DataLoader(test_fuzzers, batch_size=100, shuffle=True)\n",
    "test_generic_loader = DataLoader(test_generic, batch_size=100, shuffle=True)\n",
    "test_normal_loader = DataLoader(test_normal, batch_size=100, shuffle=True)\n",
    "test_reconnaissance_loader = DataLoader(test_reconnaissance, batch_size=100, shuffle=True)\n",
    "test_shellcode_loader = DataLoader(test_shellcode, batch_size=100, shuffle=True)\n",
    "test_worms_loader = DataLoader(test_worms, batch_size=100, shuffle=True)\n",
    "# drop_last = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e98d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 51929/52603 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_analysis.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_analysis_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_analysis = model_analysis(test_x)\n",
    "    pred = torch.max(output_test_analysis.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8d389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred\n",
       "0   3.560250e-05\n",
       "1   3.176794e-15\n",
       "2   3.897592e-23\n",
       "3   6.015347e-02\n",
       "4   7.893937e-05\n",
       "5   4.772996e-04\n",
       "6   6.015347e-02\n",
       "7   3.337896e-24\n",
       "8   4.604237e-16\n",
       "9   5.468918e-09"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data = pd.DataFrame()\n",
    "twoS_test_data[\"analysis_pred\"]=output_test_analysis.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a190ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for backdoor\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_backdoor.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_backdoor_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_backdoor.zero_grad()\n",
    "        output = model_backdoor(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_backdoor.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_backdoor_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52289fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 121573/122738 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_backdoor.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_backdoor_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_backdoor = model_backdoor(train_x)\n",
    "    pred = torch.max(output_backdoor.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67ded02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.124398e-09</td>\n",
       "      <td>8.726526e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652119e-13</td>\n",
       "      <td>5.269351e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.162503e-31</td>\n",
       "      <td>4.333672e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.420381e-14</td>\n",
       "      <td>1.953596e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.428961e-08</td>\n",
       "      <td>3.646181e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.485195e-02</td>\n",
       "      <td>1.697461e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.902930e-28</td>\n",
       "      <td>1.801602e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred\n",
       "0   1.124398e-09   8.726526e-03\n",
       "1   1.652119e-13   5.269351e-15\n",
       "2   0.000000e+00   0.000000e+00\n",
       "3   2.162503e-31   4.333672e-23\n",
       "4   0.000000e+00   0.000000e+00\n",
       "5   3.420381e-14   1.953596e-07\n",
       "6   7.428961e-08   3.646181e-03\n",
       "7   4.485195e-02   1.697461e-06\n",
       "8   2.902930e-28   1.801602e-30\n",
       "9   0.000000e+00   0.000000e+00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"backdoor_pred\"]=output_backdoor.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fca65d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 52081/52603 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_backdoor.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_backdoor_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_backdoor = model_backdoor(test_x)\n",
    "    pred = torch.max(output_test_backdoor.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfa8cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred\n",
       "0   3.560250e-05   7.887676e-03\n",
       "1   3.176794e-15   1.262875e-08\n",
       "2   3.897592e-23   1.877878e-37\n",
       "3   6.015347e-02   5.086634e-02\n",
       "4   7.893937e-05   1.182245e-01\n",
       "5   4.772996e-04   3.248699e-03\n",
       "6   6.015347e-02   5.086634e-02\n",
       "7   3.337896e-24   0.000000e+00\n",
       "8   4.604237e-16   1.471305e-12\n",
       "9   5.468918e-09   5.644661e-09"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"backdoor_pred\"]=output_test_backdoor.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7517a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for dos\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_dos.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_dos_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_dos.zero_grad()\n",
    "        output = model_dos(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_dos.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_dos_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c412b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 114173/122738 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_dos.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_dos_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_dos = model_dos(train_x)\n",
    "    pred = torch.max(output_dos.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "123f88a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.124398e-09</td>\n",
       "      <td>8.726526e-03</td>\n",
       "      <td>3.991153e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652119e-13</td>\n",
       "      <td>5.269351e-15</td>\n",
       "      <td>7.877272e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.184415e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.162503e-31</td>\n",
       "      <td>4.333672e-23</td>\n",
       "      <td>7.702916e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.420381e-14</td>\n",
       "      <td>1.953596e-07</td>\n",
       "      <td>1.376389e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.428961e-08</td>\n",
       "      <td>3.646181e-03</td>\n",
       "      <td>2.460391e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.485195e-02</td>\n",
       "      <td>1.697461e-06</td>\n",
       "      <td>7.687041e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.902930e-28</td>\n",
       "      <td>1.801602e-30</td>\n",
       "      <td>8.214868e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.610710e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred\n",
       "0   1.124398e-09   8.726526e-03  3.991153e-02\n",
       "1   1.652119e-13   5.269351e-15  7.877272e-12\n",
       "2   0.000000e+00   0.000000e+00  3.184415e-29\n",
       "3   2.162503e-31   4.333672e-23  7.702916e-23\n",
       "4   0.000000e+00   0.000000e+00  1.401298e-45\n",
       "5   3.420381e-14   1.953596e-07  1.376389e-12\n",
       "6   7.428961e-08   3.646181e-03  2.460391e-06\n",
       "7   4.485195e-02   1.697461e-06  7.687041e-02\n",
       "8   2.902930e-28   1.801602e-30  8.214868e-15\n",
       "9   0.000000e+00   0.000000e+00  1.610710e-11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"dos_pred\"]=output_dos.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62ce3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 48904/52603 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_dos.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_dos_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_dos = model_dos(test_x)\n",
    "    pred = torch.max(output_test_dos.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1d7e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03\n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13\n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12\n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01\n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01\n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03\n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01\n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16\n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13\n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"dos_pred\"]=output_test_dos.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeb8aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for exploits\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_exploits.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_exploits_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_exploits.zero_grad()\n",
    "        output = model_exploits(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_exploits.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_exploits_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47752fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 109655/122738 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_exploits.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_exploits_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_exploits = model_exploits(train_x)\n",
    "    pred = torch.max(output_exploits.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbaf267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.124398e-09</td>\n",
       "      <td>8.726526e-03</td>\n",
       "      <td>3.991153e-02</td>\n",
       "      <td>3.365455e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652119e-13</td>\n",
       "      <td>5.269351e-15</td>\n",
       "      <td>7.877272e-12</td>\n",
       "      <td>1.598304e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.184415e-29</td>\n",
       "      <td>5.632558e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.162503e-31</td>\n",
       "      <td>4.333672e-23</td>\n",
       "      <td>7.702916e-23</td>\n",
       "      <td>2.178998e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>3.570904e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.420381e-14</td>\n",
       "      <td>1.953596e-07</td>\n",
       "      <td>1.376389e-12</td>\n",
       "      <td>4.690864e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.428961e-08</td>\n",
       "      <td>3.646181e-03</td>\n",
       "      <td>2.460391e-06</td>\n",
       "      <td>9.949273e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.485195e-02</td>\n",
       "      <td>1.697461e-06</td>\n",
       "      <td>7.687041e-02</td>\n",
       "      <td>7.992063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.902930e-28</td>\n",
       "      <td>1.801602e-30</td>\n",
       "      <td>8.214868e-15</td>\n",
       "      <td>2.190658e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.610710e-11</td>\n",
       "      <td>8.385333e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred\n",
       "0   1.124398e-09   8.726526e-03  3.991153e-02   3.365455e-02\n",
       "1   1.652119e-13   5.269351e-15  7.877272e-12   1.598304e-07\n",
       "2   0.000000e+00   0.000000e+00  3.184415e-29   5.632558e-33\n",
       "3   2.162503e-31   4.333672e-23  7.702916e-23   2.178998e-24\n",
       "4   0.000000e+00   0.000000e+00  1.401298e-45   3.570904e-39\n",
       "5   3.420381e-14   1.953596e-07  1.376389e-12   4.690864e-10\n",
       "6   7.428961e-08   3.646181e-03  2.460391e-06   9.949273e-01\n",
       "7   4.485195e-02   1.697461e-06  7.687041e-02   7.992063e-01\n",
       "8   2.902930e-28   1.801602e-30  8.214868e-15   2.190658e-09\n",
       "9   0.000000e+00   0.000000e+00  1.610710e-11   8.385333e-22"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"exploits_pred\"]=output_exploits.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5100806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0,  ..., 1, 0, 0], device='cuda:0')\n",
      "correct _rate: 45506/52603 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_exploits.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_exploits_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_exploits = model_exploits(test_x)\n",
    "    pred = torch.max(output_test_exploits.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "471b6adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01\n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11\n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08\n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01\n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01\n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05\n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01\n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08\n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09\n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"exploits_pred\"]=output_test_exploits.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ed1987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 115365/122738 (94%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 49193/52603 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03\n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19\n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24\n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02\n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04\n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02\n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02\n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10\n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16\n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for fuzzers\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_fuzzers.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_fuzzers_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_fuzzers.zero_grad()\n",
    "        output = model_fuzzers(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_fuzzers.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_fuzzers_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_fuzzers.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_fuzzers_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_fuzzers = model_fuzzers(train_x)\n",
    "    pred = torch.max(output_fuzzers.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"fuzzers_pred\"]=output_fuzzers.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_fuzzers.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_fuzzers_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_fuzzers = model_fuzzers(test_x)\n",
    "    pred = torch.max(output_test_fuzzers.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"fuzzers_pred\"]=output_test_fuzzers.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f8c77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 122121/122738 (99%)\n",
      "\n",
      "tensor([0, 1, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 52325/52603 (99%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred  \n",
       "0  5.544554e-03  \n",
       "1  1.000000e+00  \n",
       "2  5.994871e-09  \n",
       "3  6.290934e-03  \n",
       "4  2.421796e-01  \n",
       "5  4.195367e-03  \n",
       "6  1.471776e-02  \n",
       "7  1.000000e+00  \n",
       "8  1.000000e+00  \n",
       "9  1.000000e+00  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for generic\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_generic.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_generic_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_generic.zero_grad()\n",
    "        output = model_generic(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_generic.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_generic_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_generic.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_generic_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_generic = model_generic(train_x)\n",
    "    pred = torch.max(output_generic.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"generic_pred\"]=output_generic.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_generic.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_generic_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_generic = model_generic(test_x)\n",
    "    pred = torch.max(output_test_generic.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"generic_pred\"]=output_test_generic.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b2c1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 116607/122738 (95%)\n",
      "\n",
      "tensor([0, 0, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 49388/52603 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "      <td>9.596084e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.249956e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "      <td>9.999993e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "      <td>2.816626e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "      <td>3.566113e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "      <td>5.092975e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "      <td>1.152405e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.053402e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.305239e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408436e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred   normal_pred  \n",
       "0  5.544554e-03  9.596084e-05  \n",
       "1  1.000000e+00  3.249956e-09  \n",
       "2  5.994871e-09  9.999993e-01  \n",
       "3  6.290934e-03  2.816626e-07  \n",
       "4  2.421796e-01  3.566113e-02  \n",
       "5  4.195367e-03  5.092975e-04  \n",
       "6  1.471776e-02  1.152405e-12  \n",
       "7  1.000000e+00  3.053402e-06  \n",
       "8  1.000000e+00  4.305239e-12  \n",
       "9  1.000000e+00  2.408436e-10  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for normal\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_normal.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_normal_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_normal.zero_grad()\n",
    "        output = model_normal(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_normal.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_normal_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_normal.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_normal_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_normal = model_normal(train_x)\n",
    "    pred = torch.max(output_normal.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"normal_pred\"]=output_normal.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_normal.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_normal_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_normal = model_normal(test_x)\n",
    "    pred = torch.max(output_test_normal.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"normal_pred\"]=output_test_normal.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5ab6c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 119371/122738 (97%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 51077/52603 (97%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "      <td>9.596084e-05</td>\n",
       "      <td>2.108540e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.249956e-09</td>\n",
       "      <td>6.647118e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>2.364401e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "      <td>2.816626e-07</td>\n",
       "      <td>5.511780e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "      <td>3.566113e-02</td>\n",
       "      <td>6.557396e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "      <td>5.092975e-04</td>\n",
       "      <td>9.699320e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "      <td>1.152405e-12</td>\n",
       "      <td>2.722271e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.053402e-06</td>\n",
       "      <td>1.455113e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.305239e-12</td>\n",
       "      <td>2.854396e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408436e-10</td>\n",
       "      <td>7.276298e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  \n",
       "0  5.544554e-03  9.596084e-05         2.108540e-01  \n",
       "1  1.000000e+00  3.249956e-09         6.647118e-09  \n",
       "2  5.994871e-09  9.999993e-01         2.364401e-12  \n",
       "3  6.290934e-03  2.816626e-07         5.511780e-02  \n",
       "4  2.421796e-01  3.566113e-02         6.557396e-09  \n",
       "5  4.195367e-03  5.092975e-04         9.699320e-01  \n",
       "6  1.471776e-02  1.152405e-12         2.722271e-02  \n",
       "7  1.000000e+00  3.053402e-06         1.455113e-23  \n",
       "8  1.000000e+00  4.305239e-12         2.854396e-12  \n",
       "9  1.000000e+00  2.408436e-10         7.276298e-09  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for reconnaissance\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_reconnaissance.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_reconnaissance_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_reconnaissance.zero_grad()\n",
    "        output = model_reconnaissance(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_reconnaissance.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_reconnaissance_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_reconnaissance.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_reconnaissance_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_reconnaissance = model_reconnaissance(train_x)\n",
    "    pred = torch.max(output_reconnaissance.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"reconnaissance_pred\"]=output_reconnaissance.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_reconnaissance.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_reconnaissance_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_reconnaissance = model_reconnaissance(test_x)\n",
    "    pred = torch.max(output_test_reconnaissance.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"reconnaissance_pred\"]=output_test_reconnaissance.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b68eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 122037/122738 (99%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 52268/52603 (99%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "      <td>9.596084e-05</td>\n",
       "      <td>2.108540e-01</td>\n",
       "      <td>1.211897e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.249956e-09</td>\n",
       "      <td>6.647118e-09</td>\n",
       "      <td>3.966620e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>2.364401e-12</td>\n",
       "      <td>1.275312e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "      <td>2.816626e-07</td>\n",
       "      <td>5.511780e-02</td>\n",
       "      <td>3.978869e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "      <td>3.566113e-02</td>\n",
       "      <td>6.557396e-09</td>\n",
       "      <td>3.080114e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "      <td>5.092975e-04</td>\n",
       "      <td>9.699320e-01</td>\n",
       "      <td>4.188878e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "      <td>1.152405e-12</td>\n",
       "      <td>2.722271e-02</td>\n",
       "      <td>7.443461e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.053402e-06</td>\n",
       "      <td>1.455113e-23</td>\n",
       "      <td>8.622137e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.305239e-12</td>\n",
       "      <td>2.854396e-12</td>\n",
       "      <td>3.015583e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408436e-10</td>\n",
       "      <td>7.276298e-09</td>\n",
       "      <td>4.455965e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \n",
       "0  5.544554e-03  9.596084e-05         2.108540e-01    1.211897e-10  \n",
       "1  1.000000e+00  3.249956e-09         6.647118e-09    3.966620e-15  \n",
       "2  5.994871e-09  9.999993e-01         2.364401e-12    1.275312e-22  \n",
       "3  6.290934e-03  2.816626e-07         5.511780e-02    3.978869e-07  \n",
       "4  2.421796e-01  3.566113e-02         6.557396e-09    3.080114e-28  \n",
       "5  4.195367e-03  5.092975e-04         9.699320e-01    4.188878e-03  \n",
       "6  1.471776e-02  1.152405e-12         2.722271e-02    7.443461e-22  \n",
       "7  1.000000e+00  3.053402e-06         1.455113e-23    8.622137e-19  \n",
       "8  1.000000e+00  4.305239e-12         2.854396e-12    3.015583e-17  \n",
       "9  1.000000e+00  2.408436e-10         7.276298e-09    4.455965e-15  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for shellcode\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_shellcode.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_shellcode_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_shellcode.zero_grad()\n",
    "        output = model_shellcode(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_shellcode.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_shellcode_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_shellcode.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_shellcode_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_shellcode = model_shellcode(train_x)\n",
    "    pred = torch.max(output_shellcode.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"shellcode_pred\"]=output_shellcode.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_shellcode.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_shellcode_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_shellcode = model_shellcode(test_x)\n",
    "    pred = torch.max(output_test_shellcode.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"shellcode_pred\"]=output_test_shellcode.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "819ee0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 122655/122738 (100%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 52566/52603 (100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "      <td>9.596084e-05</td>\n",
       "      <td>2.108540e-01</td>\n",
       "      <td>1.211897e-10</td>\n",
       "      <td>1.767702e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.249956e-09</td>\n",
       "      <td>6.647118e-09</td>\n",
       "      <td>3.966620e-15</td>\n",
       "      <td>2.588737e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>2.364401e-12</td>\n",
       "      <td>1.275312e-22</td>\n",
       "      <td>1.449428e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "      <td>2.816626e-07</td>\n",
       "      <td>5.511780e-02</td>\n",
       "      <td>3.978869e-07</td>\n",
       "      <td>1.782585e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "      <td>3.566113e-02</td>\n",
       "      <td>6.557396e-09</td>\n",
       "      <td>3.080114e-28</td>\n",
       "      <td>1.767702e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "      <td>5.092975e-04</td>\n",
       "      <td>9.699320e-01</td>\n",
       "      <td>4.188878e-03</td>\n",
       "      <td>1.655293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "      <td>1.152405e-12</td>\n",
       "      <td>2.722271e-02</td>\n",
       "      <td>7.443461e-22</td>\n",
       "      <td>3.269916e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.053402e-06</td>\n",
       "      <td>1.455113e-23</td>\n",
       "      <td>8.622137e-19</td>\n",
       "      <td>3.119740e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.305239e-12</td>\n",
       "      <td>2.854396e-12</td>\n",
       "      <td>3.015583e-17</td>\n",
       "      <td>6.671641e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408436e-10</td>\n",
       "      <td>7.276298e-09</td>\n",
       "      <td>4.455965e-15</td>\n",
       "      <td>9.368664e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  5.544554e-03  9.596084e-05         2.108540e-01    1.211897e-10   \n",
       "1  1.000000e+00  3.249956e-09         6.647118e-09    3.966620e-15   \n",
       "2  5.994871e-09  9.999993e-01         2.364401e-12    1.275312e-22   \n",
       "3  6.290934e-03  2.816626e-07         5.511780e-02    3.978869e-07   \n",
       "4  2.421796e-01  3.566113e-02         6.557396e-09    3.080114e-28   \n",
       "5  4.195367e-03  5.092975e-04         9.699320e-01    4.188878e-03   \n",
       "6  1.471776e-02  1.152405e-12         2.722271e-02    7.443461e-22   \n",
       "7  1.000000e+00  3.053402e-06         1.455113e-23    8.622137e-19   \n",
       "8  1.000000e+00  4.305239e-12         2.854396e-12    3.015583e-17   \n",
       "9  1.000000e+00  2.408436e-10         7.276298e-09    4.455965e-15   \n",
       "\n",
       "     worms_pred  \n",
       "0  1.767702e-02  \n",
       "1  2.588737e-07  \n",
       "2  1.449428e-09  \n",
       "3  1.782585e-04  \n",
       "4  1.767702e-02  \n",
       "5  1.655293e-03  \n",
       "6  3.269916e-06  \n",
       "7  3.119740e-21  \n",
       "8  6.671641e-14  \n",
       "9  9.368664e-06  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for worms\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_worms.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_worms_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_worms.zero_grad()\n",
    "        output = model_worms(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_worms.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_worms_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_worms.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_worms_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_worms = model_worms(train_x)\n",
    "    pred = torch.max(output_worms.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"worms_pred\"]=output_worms.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_worms.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_worms_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_worms = model_worms(test_x)\n",
    "    pred = torch.max(output_test_worms.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"worms_pred\"]=output_test_worms.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d92cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 10)\n",
    "        self.bc1 = nn.BatchNorm1d(100)\n",
    "        self.bc2 = nn.BatchNorm1d(100)\n",
    "        self.bc3 = nn.BatchNorm1d(100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bc1(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bc2(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bc3(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model2 = Net2()\n",
    "\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24ea048d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.124398e-09</td>\n",
       "      <td>8.726526e-03</td>\n",
       "      <td>3.991153e-02</td>\n",
       "      <td>3.365455e-02</td>\n",
       "      <td>8.710764e-02</td>\n",
       "      <td>4.430264e-03</td>\n",
       "      <td>9.014773e-02</td>\n",
       "      <td>8.154392e-01</td>\n",
       "      <td>2.590687e-01</td>\n",
       "      <td>1.482409e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652119e-13</td>\n",
       "      <td>5.269351e-15</td>\n",
       "      <td>7.877272e-12</td>\n",
       "      <td>1.598304e-07</td>\n",
       "      <td>1.411883e-24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.550684e-11</td>\n",
       "      <td>8.139295e-13</td>\n",
       "      <td>2.812653e-19</td>\n",
       "      <td>4.668656e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.184415e-29</td>\n",
       "      <td>5.632558e-33</td>\n",
       "      <td>2.063958e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236800e-06</td>\n",
       "      <td>1.617778e-06</td>\n",
       "      <td>8.691823e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.162503e-31</td>\n",
       "      <td>4.333672e-23</td>\n",
       "      <td>7.702916e-23</td>\n",
       "      <td>2.178998e-24</td>\n",
       "      <td>7.995093e-28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.208516e-14</td>\n",
       "      <td>4.049888e-07</td>\n",
       "      <td>6.476430e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>3.570904e-39</td>\n",
       "      <td>1.134889e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>1.201195e-08</td>\n",
       "      <td>4.622779e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.420381e-14</td>\n",
       "      <td>1.953596e-07</td>\n",
       "      <td>1.376389e-12</td>\n",
       "      <td>4.690864e-10</td>\n",
       "      <td>2.127114e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.798049e-09</td>\n",
       "      <td>9.179554e-10</td>\n",
       "      <td>8.819387e-15</td>\n",
       "      <td>8.719113e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.428961e-08</td>\n",
       "      <td>3.646181e-03</td>\n",
       "      <td>2.460391e-06</td>\n",
       "      <td>9.949273e-01</td>\n",
       "      <td>2.992757e-08</td>\n",
       "      <td>3.644851e-04</td>\n",
       "      <td>5.809787e-04</td>\n",
       "      <td>3.265814e-05</td>\n",
       "      <td>5.119941e-06</td>\n",
       "      <td>2.941727e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.485195e-02</td>\n",
       "      <td>1.697461e-06</td>\n",
       "      <td>7.687041e-02</td>\n",
       "      <td>7.992063e-01</td>\n",
       "      <td>9.728054e-04</td>\n",
       "      <td>1.278100e-03</td>\n",
       "      <td>1.525132e-01</td>\n",
       "      <td>3.548868e-03</td>\n",
       "      <td>2.600758e-07</td>\n",
       "      <td>8.555398e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.902930e-28</td>\n",
       "      <td>1.801602e-30</td>\n",
       "      <td>8.214868e-15</td>\n",
       "      <td>2.190658e-09</td>\n",
       "      <td>6.429720e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.628598e-12</td>\n",
       "      <td>2.794110e-11</td>\n",
       "      <td>2.299955e-15</td>\n",
       "      <td>6.133651e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.610710e-11</td>\n",
       "      <td>8.385333e-22</td>\n",
       "      <td>8.115931e-10</td>\n",
       "      <td>1.620969e-39</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.091365e-35</td>\n",
       "      <td>8.181914e-20</td>\n",
       "      <td>3.443747e-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   1.124398e-09   8.726526e-03  3.991153e-02   3.365455e-02  8.710764e-02   \n",
       "1   1.652119e-13   5.269351e-15  7.877272e-12   1.598304e-07  1.411883e-24   \n",
       "2   0.000000e+00   0.000000e+00  3.184415e-29   5.632558e-33  2.063958e-13   \n",
       "3   2.162503e-31   4.333672e-23  7.702916e-23   2.178998e-24  7.995093e-28   \n",
       "4   0.000000e+00   0.000000e+00  1.401298e-45   3.570904e-39  1.134889e-13   \n",
       "5   3.420381e-14   1.953596e-07  1.376389e-12   4.690864e-10  2.127114e-19   \n",
       "6   7.428961e-08   3.646181e-03  2.460391e-06   9.949273e-01  2.992757e-08   \n",
       "7   4.485195e-02   1.697461e-06  7.687041e-02   7.992063e-01  9.728054e-04   \n",
       "8   2.902930e-28   1.801602e-30  8.214868e-15   2.190658e-09  6.429720e-16   \n",
       "9   0.000000e+00   0.000000e+00  1.610710e-11   8.385333e-22  8.115931e-10   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  4.430264e-03  9.014773e-02         8.154392e-01    2.590687e-01   \n",
       "1  1.000000e+00  2.550684e-11         8.139295e-13    2.812653e-19   \n",
       "2  0.000000e+00  1.000000e+00         1.236800e-06    1.617778e-06   \n",
       "3  0.000000e+00  1.000000e+00         2.208516e-14    4.049888e-07   \n",
       "4  0.000000e+00  1.000000e+00         1.401298e-45    1.201195e-08   \n",
       "5  1.000000e+00  2.798049e-09         9.179554e-10    8.819387e-15   \n",
       "6  3.644851e-04  5.809787e-04         3.265814e-05    5.119941e-06   \n",
       "7  1.278100e-03  1.525132e-01         3.548868e-03    2.600758e-07   \n",
       "8  1.000000e+00  6.628598e-12         2.794110e-11    2.299955e-15   \n",
       "9  1.620969e-39  1.000000e+00         2.091365e-35    8.181914e-20   \n",
       "\n",
       "     worms_pred  \n",
       "0  1.482409e-06  \n",
       "1  4.668656e-14  \n",
       "2  8.691823e-10  \n",
       "3  6.476430e-07  \n",
       "4  4.622779e-07  \n",
       "5  8.719113e-06  \n",
       "6  2.941727e-07  \n",
       "7  8.555398e-04  \n",
       "8  6.133651e-21  \n",
       "9  3.443747e-24  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37332c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.560250e-05</td>\n",
       "      <td>7.887676e-03</td>\n",
       "      <td>7.966983e-03</td>\n",
       "      <td>7.148159e-01</td>\n",
       "      <td>7.268800e-03</td>\n",
       "      <td>5.544554e-03</td>\n",
       "      <td>9.596084e-05</td>\n",
       "      <td>2.108540e-01</td>\n",
       "      <td>1.211897e-10</td>\n",
       "      <td>1.767702e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.176794e-15</td>\n",
       "      <td>1.262875e-08</td>\n",
       "      <td>2.311947e-13</td>\n",
       "      <td>5.005984e-11</td>\n",
       "      <td>3.865425e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.249956e-09</td>\n",
       "      <td>6.647118e-09</td>\n",
       "      <td>3.966620e-15</td>\n",
       "      <td>2.588737e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.897592e-23</td>\n",
       "      <td>1.877878e-37</td>\n",
       "      <td>2.500489e-12</td>\n",
       "      <td>5.968644e-08</td>\n",
       "      <td>6.076699e-24</td>\n",
       "      <td>5.994871e-09</td>\n",
       "      <td>9.999993e-01</td>\n",
       "      <td>2.364401e-12</td>\n",
       "      <td>1.275312e-22</td>\n",
       "      <td>1.449428e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>6.070593e-02</td>\n",
       "      <td>6.290934e-03</td>\n",
       "      <td>2.816626e-07</td>\n",
       "      <td>5.511780e-02</td>\n",
       "      <td>3.978869e-07</td>\n",
       "      <td>1.782585e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.893937e-05</td>\n",
       "      <td>1.182245e-01</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>7.005392e-04</td>\n",
       "      <td>2.421796e-01</td>\n",
       "      <td>3.566113e-02</td>\n",
       "      <td>6.557396e-09</td>\n",
       "      <td>3.080114e-28</td>\n",
       "      <td>1.767702e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.772996e-04</td>\n",
       "      <td>3.248699e-03</td>\n",
       "      <td>5.440044e-03</td>\n",
       "      <td>8.574696e-05</td>\n",
       "      <td>1.181894e-02</td>\n",
       "      <td>4.195367e-03</td>\n",
       "      <td>5.092975e-04</td>\n",
       "      <td>9.699320e-01</td>\n",
       "      <td>4.188878e-03</td>\n",
       "      <td>1.655293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.015347e-02</td>\n",
       "      <td>5.086634e-02</td>\n",
       "      <td>3.403750e-01</td>\n",
       "      <td>4.163114e-01</td>\n",
       "      <td>5.579222e-02</td>\n",
       "      <td>1.471776e-02</td>\n",
       "      <td>1.152405e-12</td>\n",
       "      <td>2.722271e-02</td>\n",
       "      <td>7.443461e-22</td>\n",
       "      <td>3.269916e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.337896e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.022529e-16</td>\n",
       "      <td>2.937190e-08</td>\n",
       "      <td>9.072125e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.053402e-06</td>\n",
       "      <td>1.455113e-23</td>\n",
       "      <td>8.622137e-19</td>\n",
       "      <td>3.119740e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.604237e-16</td>\n",
       "      <td>1.471305e-12</td>\n",
       "      <td>9.431128e-13</td>\n",
       "      <td>1.007714e-09</td>\n",
       "      <td>1.271488e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.305239e-12</td>\n",
       "      <td>2.854396e-12</td>\n",
       "      <td>3.015583e-17</td>\n",
       "      <td>6.671641e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.468918e-09</td>\n",
       "      <td>5.644661e-09</td>\n",
       "      <td>2.924885e-12</td>\n",
       "      <td>1.154147e-12</td>\n",
       "      <td>8.830046e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.408436e-10</td>\n",
       "      <td>7.276298e-09</td>\n",
       "      <td>4.455965e-15</td>\n",
       "      <td>9.368664e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   3.560250e-05   7.887676e-03  7.966983e-03   7.148159e-01  7.268800e-03   \n",
       "1   3.176794e-15   1.262875e-08  2.311947e-13   5.005984e-11  3.865425e-19   \n",
       "2   3.897592e-23   1.877878e-37  2.500489e-12   5.968644e-08  6.076699e-24   \n",
       "3   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  6.070593e-02   \n",
       "4   7.893937e-05   1.182245e-01  3.403750e-01   4.163114e-01  7.005392e-04   \n",
       "5   4.772996e-04   3.248699e-03  5.440044e-03   8.574696e-05  1.181894e-02   \n",
       "6   6.015347e-02   5.086634e-02  3.403750e-01   4.163114e-01  5.579222e-02   \n",
       "7   3.337896e-24   0.000000e+00  3.022529e-16   2.937190e-08  9.072125e-10   \n",
       "8   4.604237e-16   1.471305e-12  9.431128e-13   1.007714e-09  1.271488e-16   \n",
       "9   5.468918e-09   5.644661e-09  2.924885e-12   1.154147e-12  8.830046e-14   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  5.544554e-03  9.596084e-05         2.108540e-01    1.211897e-10   \n",
       "1  1.000000e+00  3.249956e-09         6.647118e-09    3.966620e-15   \n",
       "2  5.994871e-09  9.999993e-01         2.364401e-12    1.275312e-22   \n",
       "3  6.290934e-03  2.816626e-07         5.511780e-02    3.978869e-07   \n",
       "4  2.421796e-01  3.566113e-02         6.557396e-09    3.080114e-28   \n",
       "5  4.195367e-03  5.092975e-04         9.699320e-01    4.188878e-03   \n",
       "6  1.471776e-02  1.152405e-12         2.722271e-02    7.443461e-22   \n",
       "7  1.000000e+00  3.053402e-06         1.455113e-23    8.622137e-19   \n",
       "8  1.000000e+00  4.305239e-12         2.854396e-12    3.015583e-17   \n",
       "9  1.000000e+00  2.408436e-10         7.276298e-09    4.455965e-15   \n",
       "\n",
       "     worms_pred  \n",
       "0  1.767702e-02  \n",
       "1  2.588737e-07  \n",
       "2  1.449428e-09  \n",
       "3  1.782585e-04  \n",
       "4  1.767702e-02  \n",
       "5  1.655293e-03  \n",
       "6  3.269916e-06  \n",
       "7  3.119740e-21  \n",
       "8  6.671641e-14  \n",
       "9  9.368664e-06  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "640f2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(twoS_train_data.values, dtype=torch.float32)\n",
    "train_Y = torch.tensor(attack_train.values, dtype=torch.long) \n",
    "train = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cf0b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccd6ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model2.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        output = model2(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8fc5179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48925867676734924,\n",
       " 0.4670778214931488,\n",
       " 0.46240898966789246,\n",
       " 0.4579775631427765,\n",
       " 0.4575967490673065,\n",
       " 0.4556998014450073,\n",
       " 0.4534989893436432,\n",
       " 0.45255860686302185,\n",
       " 0.45243191719055176,\n",
       " 0.45057523250579834,\n",
       " 0.4487278163433075,\n",
       " 0.448169469833374,\n",
       " 0.4482886791229248,\n",
       " 0.4476920962333679,\n",
       " 0.44587576389312744,\n",
       " 0.44570523500442505,\n",
       " 0.4458911120891571,\n",
       " 0.44520244002342224,\n",
       " 0.4453178942203522,\n",
       " 0.4445909857749939,\n",
       " 0.44441381096839905,\n",
       " 0.443867027759552,\n",
       " 0.4434124529361725,\n",
       " 0.4430859088897705,\n",
       " 0.44308799505233765,\n",
       " 0.442850798368454,\n",
       " 0.442493200302124,\n",
       " 0.44172170758247375,\n",
       " 0.4423138201236725,\n",
       " 0.4416455626487732,\n",
       " 0.44149744510650635,\n",
       " 0.44037342071533203,\n",
       " 0.4410659670829773,\n",
       " 0.44115445017814636,\n",
       " 0.44095513224601746,\n",
       " 0.4409911036491394,\n",
       " 0.4398474395275116,\n",
       " 0.44018325209617615,\n",
       " 0.44002532958984375,\n",
       " 0.43953824043273926,\n",
       " 0.4388717710971832,\n",
       " 0.4399542212486267,\n",
       " 0.43909549713134766,\n",
       " 0.4398687183856964,\n",
       " 0.43813666701316833,\n",
       " 0.43912065029144287,\n",
       " 0.43909817934036255,\n",
       " 0.4387933611869812,\n",
       " 0.43880608677864075,\n",
       " 0.4387644827365875,\n",
       " 0.4386548399925232,\n",
       " 0.43797460198402405,\n",
       " 0.4385440945625305,\n",
       " 0.43838468194007874,\n",
       " 0.4386107325553894,\n",
       " 0.4378860890865326,\n",
       " 0.4379149079322815,\n",
       " 0.4377228617668152,\n",
       " 0.43791887164115906,\n",
       " 0.43822181224823,\n",
       " 0.43760088086128235,\n",
       " 0.4369876980781555,\n",
       " 0.4370613694190979,\n",
       " 0.4376911520957947,\n",
       " 0.4372783601284027,\n",
       " 0.43663474917411804,\n",
       " 0.43717801570892334,\n",
       " 0.4371108114719391,\n",
       " 0.43676692247390747,\n",
       " 0.4363172650337219,\n",
       " 0.436642050743103,\n",
       " 0.4362224340438843,\n",
       " 0.43673157691955566,\n",
       " 0.43660974502563477,\n",
       " 0.4370133876800537,\n",
       " 0.43627476692199707,\n",
       " 0.43622082471847534,\n",
       " 0.43550223112106323,\n",
       " 0.43599626421928406,\n",
       " 0.4366014003753662,\n",
       " 0.4356900453567505,\n",
       " 0.4356059432029724,\n",
       " 0.43580806255340576,\n",
       " 0.43549054861068726,\n",
       " 0.43523314595222473,\n",
       " 0.4353814423084259,\n",
       " 0.43542131781578064,\n",
       " 0.4362046718597412,\n",
       " 0.4351460635662079,\n",
       " 0.4352175295352936,\n",
       " 0.43495574593544006,\n",
       " 0.4345252811908722,\n",
       " 0.4350889027118683,\n",
       " 0.4346420168876648,\n",
       " 0.4344561696052551,\n",
       " 0.4356502890586853,\n",
       " 0.43494829535484314,\n",
       " 0.43467408418655396,\n",
       " 0.43458524346351624,\n",
       " 0.4353681206703186,\n",
       " 0.4343019425868988,\n",
       " 0.4344642758369446,\n",
       " 0.4346131384372711,\n",
       " 0.435263067483902,\n",
       " 0.43452391028404236,\n",
       " 0.43436095118522644,\n",
       " 0.4370366632938385,\n",
       " 0.433327317237854,\n",
       " 0.43488645553588867,\n",
       " 0.43472737073898315,\n",
       " 0.434292197227478,\n",
       " 0.4348922371864319,\n",
       " 0.4343312382698059,\n",
       " 0.434437096118927,\n",
       " 0.4342096447944641,\n",
       " 0.43418315052986145,\n",
       " 0.4337717294692993,\n",
       " 0.4337148070335388,\n",
       " 0.434536337852478,\n",
       " 0.4329952597618103,\n",
       " 0.43329885601997375,\n",
       " 0.4329049587249756,\n",
       " 0.4336601495742798,\n",
       " 0.433096706867218,\n",
       " 0.43283113837242126,\n",
       " 0.43346425890922546,\n",
       " 0.43350979685783386,\n",
       " 0.4346766471862793,\n",
       " 0.4327418804168701,\n",
       " 0.43294471502304077,\n",
       " 0.43286851048469543,\n",
       " 0.43269380927085876,\n",
       " 0.4329768121242523,\n",
       " 0.4326508343219757,\n",
       " 0.4330085217952728,\n",
       " 0.4328765571117401,\n",
       " 0.43232861161231995,\n",
       " 0.43275022506713867,\n",
       " 0.4324202537536621,\n",
       " 0.432500958442688,\n",
       " 0.43278104066848755,\n",
       " 0.4321718215942383,\n",
       " 0.43245816230773926,\n",
       " 0.4316492974758148,\n",
       " 0.4310899078845978,\n",
       " 0.43223631381988525,\n",
       " 0.4342344403266907,\n",
       " 0.4319906532764435,\n",
       " 0.4318573772907257,\n",
       " 0.4326797425746918,\n",
       " 0.43293482065200806,\n",
       " 0.4346046447753906,\n",
       " 0.4327552914619446,\n",
       " 0.43258213996887207,\n",
       " 0.43188634514808655,\n",
       " 0.4320635199546814,\n",
       " 0.4321974217891693,\n",
       " 0.4317203462123871,\n",
       " 0.43162310123443604,\n",
       " 0.4321978688240051,\n",
       " 0.43171751499176025,\n",
       " 0.4317278265953064,\n",
       " 0.43158474564552307,\n",
       " 0.4310905337333679,\n",
       " 0.43222278356552124,\n",
       " 0.43187934160232544,\n",
       " 0.43123728036880493,\n",
       " 0.4312931299209595,\n",
       " 0.43262362480163574,\n",
       " 0.4312703609466553,\n",
       " 0.43149393796920776,\n",
       " 0.4311448633670807,\n",
       " 0.4309728443622589,\n",
       " 0.4312244951725006,\n",
       " 0.4313277304172516,\n",
       " 0.4309627115726471,\n",
       " 0.4313301742076874,\n",
       " 0.4316035211086273,\n",
       " 0.431925892829895,\n",
       " 0.43117237091064453,\n",
       " 0.43169164657592773,\n",
       " 0.43144717812538147,\n",
       " 0.431533545255661,\n",
       " 0.4314172863960266,\n",
       " 0.4301726818084717,\n",
       " 0.43057090044021606,\n",
       " 0.43150898814201355,\n",
       " 0.4310166537761688,\n",
       " 0.43077772855758667,\n",
       " 0.43032070994377136,\n",
       " 0.4317827522754669,\n",
       " 0.4301965534687042,\n",
       " 0.4314049184322357,\n",
       " 0.43115660548210144,\n",
       " 0.4308831989765167,\n",
       " 0.43081527948379517,\n",
       " 0.430767685174942,\n",
       " 0.4308820068836212,\n",
       " 0.43156272172927856,\n",
       " 0.4301561713218689,\n",
       " 0.43103036284446716,\n",
       " 0.43049824237823486,\n",
       " 0.4305112063884735,\n",
       " 0.42971497774124146,\n",
       " 0.43024635314941406,\n",
       " 0.43062037229537964,\n",
       " 0.4299626052379608,\n",
       " 0.4308839440345764,\n",
       " 0.4303438067436218,\n",
       " 0.43026626110076904,\n",
       " 0.42922255396842957,\n",
       " 0.4293716847896576,\n",
       " 0.4301552474498749,\n",
       " 0.431113600730896,\n",
       " 0.430615097284317,\n",
       " 0.43022677302360535,\n",
       " 0.4295141100883484,\n",
       " 0.432059109210968,\n",
       " 0.43049952387809753,\n",
       " 0.4295406639575958,\n",
       " 0.43048790097236633,\n",
       " 0.4305478036403656,\n",
       " 0.4303314983844757,\n",
       " 0.4311527907848358,\n",
       " 0.42904889583587646,\n",
       " 0.42983660101890564,\n",
       " 0.4294545650482178,\n",
       " 0.43003392219543457,\n",
       " 0.4300783574581146,\n",
       " 0.4293046295642853,\n",
       " 0.42899090051651,\n",
       " 0.42980289459228516,\n",
       " 0.43102365732192993,\n",
       " 0.42936277389526367,\n",
       " 0.4298415780067444,\n",
       " 0.42998620867729187,\n",
       " 0.43061453104019165,\n",
       " 0.43000587821006775,\n",
       " 0.4290432333946228,\n",
       " 0.42963096499443054,\n",
       " 0.4304249882698059,\n",
       " 0.42873701453208923,\n",
       " 0.429680734872818,\n",
       " 0.42950406670570374,\n",
       " 0.43055638670921326,\n",
       " 0.42908626794815063,\n",
       " 0.4292738437652588,\n",
       " 0.4291996657848358,\n",
       " 0.42848920822143555,\n",
       " 0.42933017015457153,\n",
       " 0.42980384826660156,\n",
       " 0.4301660358905792,\n",
       " 0.4292218089103699,\n",
       " 0.4292713701725006,\n",
       " 0.4292120635509491,\n",
       " 0.4293859004974365,\n",
       " 0.42929914593696594,\n",
       " 0.4292062520980835,\n",
       " 0.4298551678657532,\n",
       " 0.42983198165893555,\n",
       " 0.4280676245689392,\n",
       " 0.4289012849330902,\n",
       " 0.42959895730018616,\n",
       " 0.42924875020980835,\n",
       " 0.42846110463142395,\n",
       " 0.4288814663887024,\n",
       " 0.4294344484806061,\n",
       " 0.430033415555954,\n",
       " 0.42918360233306885,\n",
       " 0.429208904504776,\n",
       " 0.42855697870254517,\n",
       " 0.4295881688594818,\n",
       " 0.42999985814094543,\n",
       " 0.4286877512931824,\n",
       " 0.42899248003959656,\n",
       " 0.42876550555229187,\n",
       " 0.42907559871673584,\n",
       " 0.4290889501571655,\n",
       " 0.4289315640926361,\n",
       " 0.43038949370384216,\n",
       " 0.42867738008499146,\n",
       " 0.4304684102535248,\n",
       " 0.4282856583595276,\n",
       " 0.4293629229068756,\n",
       " 0.4285414218902588,\n",
       " 0.42880958318710327,\n",
       " 0.4288797676563263,\n",
       " 0.4300435483455658,\n",
       " 0.4303545355796814,\n",
       " 0.4305030107498169,\n",
       " 0.4300019443035126,\n",
       " 0.42884886264801025,\n",
       " 0.4296334683895111,\n",
       " 0.4296119809150696,\n",
       " 0.4287460148334503,\n",
       " 0.4279285967350006,\n",
       " 0.4278619885444641,\n",
       " 0.42848414182662964,\n",
       " 0.428692489862442,\n",
       " 0.4286762773990631]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b390be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 5, 6,  ..., 3, 5, 4], device='cuda:0')\n",
      "correct _rate: 101267/122738 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model2.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output = model2(train_x)\n",
    "    pred = torch.max(output.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f1e99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.tensor(twoS_test_data.values, dtype=torch.float32)\n",
    "test_Y = torch.tensor(attack_test.values, dtype=torch.long) \n",
    "\n",
    "test = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8329e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 41586/52603 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model2.eval()\n",
    "    correct = 0\n",
    "    pred_list = list()\n",
    "    test_y_list = list()\n",
    "    for test_x, test_y in test_loader:\n",
    "        test_x, test_y = Variable(test_x), Variable(test_y)\n",
    "        test_y_list.extend(test_y.to('cpu').detach().numpy().tolist())\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        output = model2(test_x)\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        pred_list.extend(pred.to('cpu').detach().numpy().tolist())\n",
    "        correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_loader.dataset)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8edd80a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905632758587913"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e555e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319364526518335"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "faf4316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4741092631257362"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6abfbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47478718784300983"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5700540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   48     0    73   449     4     9     3     4     7    15]\n",
      " [    0    22    15   471     3     1     2     4     2     0]\n",
      " [    6     2   150  3371    62    23    19    20    29    17]\n",
      " [   51    26   217  9110   226   266    89    66    32    39]\n",
      " [    9     3    31   676  3402    29  1092    56    32     9]\n",
      " [    1     0    12   225    16 11853     2     4     6     2]\n",
      " [   38     1   206   208  1140    97 14827    55   100    20]\n",
      " [    0    17    72   865    54    69    40  2002     5     2]\n",
      " [    0     0     5    65    66     0     9    21   171     0]\n",
      " [    1     0     2    24     2     4     1     0     0     1]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_y_list, pred_list, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bfda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "445269f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "159c367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75670d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911168505271391"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96e286cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(twoS_test_data, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac6330c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762675132597"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_test_data, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70498b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911168505271391"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7f15b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968747029637093"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_train_norm, attack_train)\n",
    "clf.score(testdata_norm, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "317d1ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9106226270592644"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(data_train_norm, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c92cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

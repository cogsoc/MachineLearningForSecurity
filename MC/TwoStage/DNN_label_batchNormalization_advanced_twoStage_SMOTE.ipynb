{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804e8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "970288d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "# https://research.unsw.edu.au/projects/unsw-nb15-dataset\n",
    "# According to the website above csv is wrongly saved, so I change the name\n",
    "# The number of records in the training set is 175,341 records and the testing set is 82,332 records from the different types, attack and normal.\n",
    "df = pd.read_csv('../../Data/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d76a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "# Pytorch\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc8caeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>attack_cat_Analysis</th>\n",
       "      <th>attack_cat_Backdoor</th>\n",
       "      <th>attack_cat_DoS</th>\n",
       "      <th>attack_cat_Exploits</th>\n",
       "      <th>attack_cat_Fuzzers</th>\n",
       "      <th>attack_cat_Generic</th>\n",
       "      <th>attack_cat_Normal</th>\n",
       "      <th>attack_cat_Reconnaissance</th>\n",
       "      <th>attack_cat_Shellcode</th>\n",
       "      <th>attack_cat_Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>39.417980</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.637109</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>26.683033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.521584</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>32.593026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.542905</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>31.313031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.258687</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>57.985135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.121478    113        0      2      6      4     258     172   \n",
       "1   2  0.649902    113        0      2     14     38     734   42014   \n",
       "2   3  1.623129    113        0      2      8     16     364   13186   \n",
       "3   4  1.681642    113        3      2     12     12     628     770   \n",
       "4   5  0.449454    113        0      2     10      6     534     268   \n",
       "5   6  0.380537    113        0      2     10      6     534     268   \n",
       "6   7  0.637109    113        0      2     10      8     534     354   \n",
       "7   8  0.521584    113        0      2     10      8     534     354   \n",
       "8   9  0.542905    113        0      2     10      8     534     354   \n",
       "9  10  0.258687    113        0      2     10      6     534     268   \n",
       "\n",
       "        rate  ...  attack_cat_Analysis  attack_cat_Backdoor  attack_cat_DoS  \\\n",
       "0  74.087490  ...                    0                    0               0   \n",
       "1  78.473372  ...                    0                    0               0   \n",
       "2  14.170161  ...                    0                    0               0   \n",
       "3  13.677108  ...                    0                    0               0   \n",
       "4  33.373826  ...                    0                    0               0   \n",
       "5  39.417980  ...                    0                    0               0   \n",
       "6  26.683033  ...                    0                    0               0   \n",
       "7  32.593026  ...                    0                    0               0   \n",
       "8  31.313031  ...                    0                    0               0   \n",
       "9  57.985135  ...                    0                    0               0   \n",
       "\n",
       "   attack_cat_Exploits  attack_cat_Fuzzers  attack_cat_Generic  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   0   \n",
       "3                    0                   0                   0   \n",
       "4                    0                   0                   0   \n",
       "5                    0                   0                   0   \n",
       "6                    0                   0                   0   \n",
       "7                    0                   0                   0   \n",
       "8                    0                   0                   0   \n",
       "9                    0                   0                   0   \n",
       "\n",
       "   attack_cat_Normal  attack_cat_Reconnaissance  attack_cat_Shellcode  \\\n",
       "0                  1                          0                     0   \n",
       "1                  1                          0                     0   \n",
       "2                  1                          0                     0   \n",
       "3                  1                          0                     0   \n",
       "4                  1                          0                     0   \n",
       "5                  1                          0                     0   \n",
       "6                  1                          0                     0   \n",
       "7                  1                          0                     0   \n",
       "8                  1                          0                     0   \n",
       "9                  1                          0                     0   \n",
       "\n",
       "   attack_cat_Worms  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nominal to numeric of data\n",
    "# proto                 object\n",
    "# service               object\n",
    "# state                 object\n",
    "\n",
    "# proto to numeric\n",
    "# proto_mapping = {'xxx':2, 'xxx':1, 'xxx':0}\n",
    "# data['proto'] = data['proto'].map(proto_mapping)\n",
    "\n",
    "# proto to numeric\n",
    "proto_le = LabelEncoder()\n",
    "df['proto'] = proto_le.fit_transform(df['proto'])\n",
    " \n",
    "# service to numeric\n",
    "service_le = LabelEncoder()\n",
    "df['service'] = service_le.fit_transform(df['service'])\n",
    "\n",
    "# state to numeric\n",
    "state_le = LabelEncoder()\n",
    "df['state'] = state_le.fit_transform(df['state'])\n",
    "\n",
    "# nominal to numeric of data\n",
    "# attack_cat            object\n",
    "\n",
    "# target to numeric\n",
    "df['attack_cat2']=df['attack_cat']\n",
    "attack_cat2_le = LabelEncoder()\n",
    "df['attack_cat2'] = attack_cat2_le.fit_transform(df['attack_cat2'])\n",
    "df_processed = pd.get_dummies(df, columns=(['attack_cat']))\n",
    "\n",
    "\n",
    "df_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ebc8a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>attack_cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.380537</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>39.417980</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.637109</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>26.683033</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.521584</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>32.593026</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.542905</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>534</td>\n",
       "      <td>354</td>\n",
       "      <td>31.313031</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.258687</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>57.985135</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.121478    113        0      2      6      4     258     172   \n",
       "1   2  0.649902    113        0      2     14     38     734   42014   \n",
       "2   3  1.623129    113        0      2      8     16     364   13186   \n",
       "3   4  1.681642    113        3      2     12     12     628     770   \n",
       "4   5  0.449454    113        0      2     10      6     534     268   \n",
       "5   6  0.380537    113        0      2     10      6     534     268   \n",
       "6   7  0.637109    113        0      2     10      8     534     354   \n",
       "7   8  0.521584    113        0      2     10      8     534     354   \n",
       "8   9  0.542905    113        0      2     10      8     534     354   \n",
       "9  10  0.258687    113        0      2     10      6     534     268   \n",
       "\n",
       "        rate  ...  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  \\\n",
       "0  74.087490  ...               1             0           0                 0   \n",
       "1  78.473372  ...               2             0           0                 0   \n",
       "2  14.170161  ...               3             0           0                 0   \n",
       "3  13.677108  ...               3             1           1                 0   \n",
       "4  33.373826  ...              40             0           0                 0   \n",
       "5  39.417980  ...              40             0           0                 0   \n",
       "6  26.683033  ...              40             0           0                 0   \n",
       "7  32.593026  ...              40             0           0                 0   \n",
       "8  31.313031  ...              40             0           0                 0   \n",
       "9  57.985135  ...              40             0           0                 0   \n",
       "\n",
       "   ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  label  attack_cat2  \n",
       "0           1           1                0      Normal      0            6  \n",
       "1           1           6                0      Normal      0            6  \n",
       "2           2           6                0      Normal      0            6  \n",
       "3           2           1                0      Normal      0            6  \n",
       "4           2          39                0      Normal      0            6  \n",
       "5           2          39                0      Normal      0            6  \n",
       "6           1          39                0      Normal      0            6  \n",
       "7           3          39                0      Normal      0            6  \n",
       "8           3          39                0      Normal      0            6  \n",
       "9           3          39                0      Normal      0            6  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "853d725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "sm = SMOTE()\n",
    "\n",
    "label_train = df.iloc[:,-2]\n",
    "\n",
    "data_rebalanced, label_rebalanced = sm.fit_resample(df_processed, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9edf98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(data_rebalanced, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1867627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167077, 55)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train.dtypes\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d3234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>attack_cat_Analysis</th>\n",
       "      <th>attack_cat_Backdoor</th>\n",
       "      <th>attack_cat_DoS</th>\n",
       "      <th>attack_cat_Exploits</th>\n",
       "      <th>attack_cat_Fuzzers</th>\n",
       "      <th>attack_cat_Generic</th>\n",
       "      <th>attack_cat_Normal</th>\n",
       "      <th>attack_cat_Reconnaissance</th>\n",
       "      <th>attack_cat_Shellcode</th>\n",
       "      <th>attack_cat_Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208167</th>\n",
       "      <td>14119</td>\n",
       "      <td>0.118954</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>4002</td>\n",
       "      <td>2657</td>\n",
       "      <td>2500.286578</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117281</th>\n",
       "      <td>117282</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.000300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107751</th>\n",
       "      <td>107752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232733</th>\n",
       "      <td>17964</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>3717</td>\n",
       "      <td>2437</td>\n",
       "      <td>7991.992287</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129951</th>\n",
       "      <td>129952</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.000300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237859</th>\n",
       "      <td>24407</td>\n",
       "      <td>4.438847</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>410</td>\n",
       "      <td>12961</td>\n",
       "      <td>501661</td>\n",
       "      <td>149.569277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65132</th>\n",
       "      <td>65133</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.002500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46842</th>\n",
       "      <td>46843</td>\n",
       "      <td>0.572216</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>978</td>\n",
       "      <td>86</td>\n",
       "      <td>12.233143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88324</th>\n",
       "      <td>88325</td>\n",
       "      <td>1.671502</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>1334</td>\n",
       "      <td>1638</td>\n",
       "      <td>28.118423</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107709</th>\n",
       "      <td>107710</td>\n",
       "      <td>0.483477</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>1010</td>\n",
       "      <td>39.298664</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "208167   14119  0.118954    113        0      2     20     21    4002    2657   \n",
       "117281  117282  0.000008    119        2      3      2      0     114       0   \n",
       "107751  107752  0.000000      6        0      3      1      0      46       0   \n",
       "232733   17964  0.004629    113        0      2     18     18    3717    2437   \n",
       "129951  129952  0.000008    120        0      3      2      0     200       0   \n",
       "237859   24407  4.438847    113        0      2    224    410   12961  501661   \n",
       "65132    65133  0.000010     97        0      3      2      0     200       0   \n",
       "46842    46843  0.572216    113        0      0      6      2     978      86   \n",
       "88324    88325  1.671502    113        3      2     26     22    1334    1638   \n",
       "107709  107710  0.483477    113        5      2     12      8     858    1010   \n",
       "\n",
       "                 rate  ...  attack_cat_Analysis  attack_cat_Backdoor  \\\n",
       "208167    2500.286578  ...                    0                    0   \n",
       "117281  125000.000300  ...                    0                    0   \n",
       "107751       0.000000  ...                    0                    0   \n",
       "232733    7991.992287  ...                    0                    0   \n",
       "129951  125000.000300  ...                    0                    0   \n",
       "237859     149.569277  ...                    0                    0   \n",
       "65132   100000.002500  ...                    0                    0   \n",
       "46842       12.233143  ...                    0                    0   \n",
       "88324       28.118423  ...                    0                    0   \n",
       "107709      39.298664  ...                    0                    0   \n",
       "\n",
       "        attack_cat_DoS  attack_cat_Exploits  attack_cat_Fuzzers  \\\n",
       "208167               0                    0                   0   \n",
       "117281               0                    0                   0   \n",
       "107751               0                    0                   0   \n",
       "232733               0                    0                   0   \n",
       "129951               0                    1                   0   \n",
       "237859               0                    0                   0   \n",
       "65132                0                    1                   0   \n",
       "46842                0                    0                   0   \n",
       "88324                0                    1                   0   \n",
       "107709               1                    0                   0   \n",
       "\n",
       "        attack_cat_Generic  attack_cat_Normal  attack_cat_Reconnaissance  \\\n",
       "208167                   0                  1                          0   \n",
       "117281                   1                  0                          0   \n",
       "107751                   0                  1                          0   \n",
       "232733                   0                  1                          0   \n",
       "129951                   0                  0                          0   \n",
       "237859                   0                  1                          0   \n",
       "65132                    0                  0                          0   \n",
       "46842                    0                  1                          0   \n",
       "88324                    0                  0                          0   \n",
       "107709                   0                  0                          0   \n",
       "\n",
       "        attack_cat_Shellcode  attack_cat_Worms  \n",
       "208167                     0                 0  \n",
       "117281                     0                 0  \n",
       "107751                     0                 0  \n",
       "232733                     0                 0  \n",
       "129951                     0                 0  \n",
       "237859                     0                 0  \n",
       "65132                      0                 0  \n",
       "46842                      0                 0  \n",
       "88324                      0                 0  \n",
       "107709                     0                 0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6d9dad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208167</th>\n",
       "      <td>0.118954</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>4002</td>\n",
       "      <td>2657</td>\n",
       "      <td>2500.286578</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117281</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.000300</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107751</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232733</th>\n",
       "      <td>0.004629</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>3717</td>\n",
       "      <td>2437</td>\n",
       "      <td>7991.992287</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129951</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.000300</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237859</th>\n",
       "      <td>4.438847</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>410</td>\n",
       "      <td>12961</td>\n",
       "      <td>501661</td>\n",
       "      <td>149.569277</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65132</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.002500</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46842</th>\n",
       "      <td>0.572216</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>978</td>\n",
       "      <td>86</td>\n",
       "      <td>12.233143</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88324</th>\n",
       "      <td>1.671502</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>1334</td>\n",
       "      <td>1638</td>\n",
       "      <td>28.118423</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107709</th>\n",
       "      <td>0.483477</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>1010</td>\n",
       "      <td>39.298664</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "208167  0.118954    113        0      2     20     21    4002    2657   \n",
       "117281  0.000008    119        2      3      2      0     114       0   \n",
       "107751  0.000000      6        0      3      1      0      46       0   \n",
       "232733  0.004629    113        0      2     18     18    3717    2437   \n",
       "129951  0.000008    120        0      3      2      0     200       0   \n",
       "237859  4.438847    113        0      2    224    410   12961  501661   \n",
       "65132   0.000010     97        0      3      2      0     200       0   \n",
       "46842   0.572216    113        0      0      6      2     978      86   \n",
       "88324   1.671502    113        3      2     26     22    1334    1638   \n",
       "107709  0.483477    113        5      2     12      8     858    1010   \n",
       "\n",
       "                 rate  sttl  ...  ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "208167    2500.286578    31  ...           5                 1   \n",
       "117281  125000.000300   254  ...          18                18   \n",
       "107751       0.000000     0  ...           2                 2   \n",
       "232733    7991.992287    31  ...           1                 1   \n",
       "129951  125000.000300   254  ...           2                 2   \n",
       "237859     149.569277    31  ...           4                 1   \n",
       "65132   100000.002500   254  ...           2                 2   \n",
       "46842       12.233143    62  ...           4                 3   \n",
       "88324       28.118423    62  ...           2                 1   \n",
       "107709      39.298664    62  ...           1                 1   \n",
       "\n",
       "        ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "208167                 1               6             0           0   \n",
       "117281                18              18             0           0   \n",
       "107751                 2               2             0           0   \n",
       "232733                 1               3             0           0   \n",
       "129951                 2               5             0           0   \n",
       "237859                 1               3             0           0   \n",
       "65132                  2               4             0           0   \n",
       "46842                  1               3             0           0   \n",
       "88324                  1               3             1           1   \n",
       "107709                 1               1             0           0   \n",
       "\n",
       "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "208167                 0           6           8                0  \n",
       "117281                 0          19          18                0  \n",
       "107751                 0           2           2                1  \n",
       "232733                 0           1           7                0  \n",
       "129951                 0           5           5                0  \n",
       "237859                 0           1          10                0  \n",
       "65132                  0           4           4                0  \n",
       "46842                  0           3           3                0  \n",
       "88324                  0           3           1                0  \n",
       "107709                 1           1           1                0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = df_train.drop(['id', 'label', 'attack_cat2','attack_cat_Analysis','attack_cat_Backdoor','attack_cat_DoS','attack_cat_Exploits','attack_cat_Fuzzers','attack_cat_Generic','attack_cat_Normal','attack_cat_Reconnaissance','attack_cat_Shellcode','attack_cat_Worms'], axis=1)\n",
    "analysis_train = df_train.iloc[:,-10]\n",
    "backdoor_train = df_train.iloc[:,-9]\n",
    "dos_train = df_train.iloc[:,-8]\n",
    "exploits_train = df_train.iloc[:,-7]\n",
    "fuzzers_train = df_train.iloc[:,-6]\n",
    "generic_train = df_train.iloc[:,-5]\n",
    "normal_train = df_train.iloc[:,-4]\n",
    "reconnaissance_train = df_train.iloc[:,-3]\n",
    "shellcode_train = df_train.iloc[:,-2]\n",
    "worms_train = df_train.iloc[:,-1]\n",
    "\n",
    "attack_train = df_train.iloc[:,-11]\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08f8a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max scaling\n",
    "data_train_norm = (data_train - data_train.min()) / (data_train.max() - data_train.min())\n",
    "data_train_norm = data_train_norm.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "653d050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208167</th>\n",
       "      <td>1.982563e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>3.060501e-04</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117281</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.170364e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107751</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.255546e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232733</th>\n",
       "      <td>7.715199e-05</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>2.840681e-04</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129951</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.280351e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237859</th>\n",
       "      <td>7.398080e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.037788</td>\n",
       "      <td>9.970537e-04</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65132</th>\n",
       "      <td>1.666667e-07</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.280351e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46842</th>\n",
       "      <td>9.536935e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>7.281030e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88324</th>\n",
       "      <td>2.785837e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>1.002684e-04</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107709</th>\n",
       "      <td>8.057951e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>6.355475e-05</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dur     proto   service     state     spkts     dpkts  \\\n",
       "208167  1.982563e-03  0.856061  0.000000  0.285714  0.001976  0.001935   \n",
       "117281  1.333334e-07  0.901515  0.166667  0.428571  0.000104  0.000000   \n",
       "107751  0.000000e+00  0.045455  0.000000  0.428571  0.000000  0.000000   \n",
       "232733  7.715199e-05  0.856061  0.000000  0.285714  0.001768  0.001659   \n",
       "129951  1.333334e-07  0.909091  0.000000  0.428571  0.000104  0.000000   \n",
       "237859  7.398080e-02  0.856061  0.000000  0.285714  0.023193  0.037788   \n",
       "65132   1.666667e-07  0.734848  0.000000  0.428571  0.000104  0.000000   \n",
       "46842   9.536935e-03  0.856061  0.000000  0.000000  0.000520  0.000184   \n",
       "88324   2.785837e-02  0.856061  0.250000  0.285714  0.002600  0.002028   \n",
       "107709  8.057951e-03  0.856061  0.416667  0.285714  0.001144  0.000737   \n",
       "\n",
       "              sbytes    dbytes      rate      sttl  ...  ct_dst_ltm  \\\n",
       "208167  3.060501e-04  0.000183  0.002500  0.121569  ...        0.08   \n",
       "117281  6.170364e-06  0.000000  0.125000  0.996078  ...        0.34   \n",
       "107751  9.255546e-07  0.000000  0.000000  0.000000  ...        0.02   \n",
       "232733  2.840681e-04  0.000168  0.007992  0.121569  ...        0.00   \n",
       "129951  1.280351e-05  0.000000  0.125000  0.996078  ...        0.02   \n",
       "237859  9.970537e-04  0.034617  0.000150  0.121569  ...        0.06   \n",
       "65132   1.280351e-05  0.000000  0.100000  0.996078  ...        0.02   \n",
       "46842   7.281030e-05  0.000006  0.000012  0.243137  ...        0.06   \n",
       "88324   1.002684e-04  0.000113  0.000028  0.243137  ...        0.02   \n",
       "107709  6.355475e-05  0.000070  0.000039  0.243137  ...        0.00   \n",
       "\n",
       "        ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "208167              0.00          0.000000        0.080645          0.00   \n",
       "117281              0.34          0.377778        0.274194          0.00   \n",
       "107751              0.02          0.022222        0.016129          0.00   \n",
       "232733              0.00          0.000000        0.032258          0.00   \n",
       "129951              0.02          0.022222        0.064516          0.00   \n",
       "237859              0.00          0.000000        0.032258          0.00   \n",
       "65132               0.02          0.022222        0.048387          0.00   \n",
       "46842               0.04          0.000000        0.032258          0.00   \n",
       "88324               0.00          0.000000        0.032258          0.25   \n",
       "107709              0.00          0.000000        0.000000          0.00   \n",
       "\n",
       "        ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "208167        0.00          0.000000    0.084746    0.114754              0.0  \n",
       "117281        0.00          0.000000    0.305085    0.278689              0.0  \n",
       "107751        0.00          0.000000    0.016949    0.016393              1.0  \n",
       "232733        0.00          0.000000    0.000000    0.098361              0.0  \n",
       "129951        0.00          0.000000    0.067797    0.065574              0.0  \n",
       "237859        0.00          0.000000    0.000000    0.147541              0.0  \n",
       "65132         0.00          0.000000    0.050847    0.049180              0.0  \n",
       "46842         0.00          0.000000    0.033898    0.032787              0.0  \n",
       "88324         0.25          0.000000    0.033898    0.000000              0.0  \n",
       "107709        0.00          0.033333    0.000000    0.000000              0.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_norm.shape\n",
    "data_train_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccd5a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing 10 types of binary classification set\n",
    "train_X = torch.tensor(data_train_norm.values, dtype=torch.float32)\n",
    "\n",
    "train_analysis_Y = torch.tensor(analysis_train.values, dtype=torch.long) \n",
    "train_backdoor_Y = torch.tensor(backdoor_train.values, dtype=torch.long) \n",
    "train_dos_Y = torch.tensor(dos_train.values, dtype=torch.long) \n",
    "train_exploits_Y = torch.tensor(exploits_train.values, dtype=torch.long) \n",
    "train_fuzzers_Y = torch.tensor(fuzzers_train.values, dtype=torch.long) \n",
    "train_generic_Y = torch.tensor(generic_train.values, dtype=torch.long) \n",
    "train_normal_Y = torch.tensor(normal_train.values, dtype=torch.long) \n",
    "train_reconnaissance_Y = torch.tensor(reconnaissance_train.values, dtype=torch.long) \n",
    "train_shellcode_Y = torch.tensor(shellcode_train.values, dtype=torch.long) \n",
    "train_worms_Y = torch.tensor(worms_train.values, dtype=torch.long) \n",
    "\n",
    "train_analysis = TensorDataset(train_X, train_analysis_Y)\n",
    "train_backdoor = TensorDataset(train_X, train_backdoor_Y)\n",
    "train_dos = TensorDataset(train_X, train_dos_Y)\n",
    "train_exploits = TensorDataset(train_X, train_exploits_Y)\n",
    "train_fuzzers = TensorDataset(train_X, train_fuzzers_Y)\n",
    "train_generic = TensorDataset(train_X, train_generic_Y)\n",
    "train_normal = TensorDataset(train_X, train_normal_Y)\n",
    "train_reconnaissance = TensorDataset(train_X, train_reconnaissance_Y)\n",
    "train_shellcode = TensorDataset(train_X, train_shellcode_Y)\n",
    "train_worms = TensorDataset(train_X, train_worms_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed42e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analysis_loader = DataLoader(train_analysis, batch_size=100, shuffle=True)\n",
    "train_backdoor_loader = DataLoader(train_backdoor, batch_size=100, shuffle=True)\n",
    "train_dos_loader = DataLoader(train_dos, batch_size=100, shuffle=True)\n",
    "train_exploits_loader = DataLoader(train_exploits, batch_size=100, shuffle=True)\n",
    "train_fuzzers_loader = DataLoader(train_fuzzers, batch_size=100, shuffle=True)\n",
    "train_generic_loader = DataLoader(train_generic, batch_size=100, shuffle=True)\n",
    "train_normal_loader = DataLoader(train_normal, batch_size=100, shuffle=True)\n",
    "train_reconnaissance_loader = DataLoader(train_reconnaissance, batch_size=100, shuffle=True)\n",
    "train_shellcode_loader = DataLoader(train_shellcode, batch_size=100, shuffle=True)\n",
    "train_worms_loader = DataLoader(train_worms, batch_size=100, shuffle=True)\n",
    "# drop_last = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a06bdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 2)\n",
    "        self.bc1 = nn.BatchNorm1d(100)\n",
    "        self.bc2 = nn.BatchNorm1d(100)\n",
    "        self.bc3 = nn.BatchNorm1d(100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bc1(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bc2(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bc3(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model_analysis = Net()\n",
    "model_backdoor = Net()\n",
    "model_dos = Net()\n",
    "model_exploits = Net()\n",
    "model_fuzzers = Net()\n",
    "model_generic = Net()\n",
    "model_normal = Net()\n",
    "model_reconnaissance = Net()\n",
    "model_shellcode = Net()\n",
    "model_worms = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "715a1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f96aed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_analysis = model_analysis.to(device)\n",
    "model_backdoor = model_backdoor.to(device)\n",
    "model_dos = model_dos.to(device)\n",
    "model_exploits = model_exploits.to(device)\n",
    "model_fuzzers = model_fuzzers.to(device)\n",
    "model_generic = model_generic.to(device)\n",
    "model_normal = model_normal.to(device)\n",
    "model_reconnaissance = model_reconnaissance.to(device)\n",
    "model_shellcode = model_shellcode.to(device)\n",
    "model_worms = model_worms.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbc76076",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd985de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.03)\n",
    "optimizer_analysis = torch.optim.Adam(model_analysis.parameters(), lr=0.03)\n",
    "optimizer_backdoor = torch.optim.Adam(model_backdoor.parameters(), lr=0.03)\n",
    "optimizer_dos = torch.optim.Adam(model_dos.parameters(), lr=0.03)\n",
    "optimizer_exploits = torch.optim.Adam(model_exploits.parameters(), lr=0.03)\n",
    "optimizer_fuzzers = torch.optim.Adam(model_fuzzers.parameters(), lr=0.03)\n",
    "optimizer_generic = torch.optim.Adam(model_generic.parameters(), lr=0.03)\n",
    "optimizer_normal = torch.optim.Adam(model_normal.parameters(), lr=0.03)\n",
    "optimizer_reconnaissance = torch.optim.Adam(model_reconnaissance.parameters(), lr=0.03)\n",
    "optimizer_shellcode = torch.optim.Adam(model_shellcode.parameters(), lr=0.03)\n",
    "optimizer_worms = torch.optim.Adam(model_worms.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5348cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the machine learning model\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_analysis.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_analysis_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_analysis.zero_grad()\n",
    "        output = model_analysis(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_analysis.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_analysis_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce234cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 165814/167077 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_analysis.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_analysis_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_analysis = model_analysis(train_x)\n",
    "    pred = torch.max(output_analysis.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63b7946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b304bd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.733373e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435122e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950863e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090117e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.804679e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.157892e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.733348e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.574244e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.273745e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred\n",
       "0   5.733373e-29\n",
       "1   3.435122e-08\n",
       "2   5.950863e-20\n",
       "3   1.090117e-15\n",
       "4   4.804679e-02\n",
       "5   4.157892e-20\n",
       "6   4.804679e-02\n",
       "7   8.733348e-22\n",
       "8   1.574244e-08\n",
       "9   6.273745e-03"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data = pd.DataFrame()\n",
    "twoS_train_data[\"analysis_pred\"]=output_analysis.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd2997ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83703</th>\n",
       "      <td>6.743185e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215281</th>\n",
       "      <td>5.651618e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66227</th>\n",
       "      <td>1.004220e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104554</th>\n",
       "      <td>1.354457e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92327</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106343</th>\n",
       "      <td>1.166667e-07</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130089</th>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231026</th>\n",
       "      <td>1.722326e-02</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147844</th>\n",
       "      <td>5.000001e-08</td>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58003</th>\n",
       "      <td>5.990434e-03</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dur     proto   service  state     spkts     dpkts    sbytes  \\\n",
       "83703   6.743185e-03  0.856061  0.416667  0.250  0.000948  0.000547  0.000065   \n",
       "215281  5.651618e-03  0.856061  0.000000  0.250  0.000948  0.000547  0.000155   \n",
       "66227   1.004220e-02  0.856061  0.000000  0.250  0.001159  0.000729  0.000079   \n",
       "104554  1.354457e-02  0.856061  0.000000  0.250  0.001159  0.000911  0.000077   \n",
       "92327   1.333334e-07  0.856061  0.000000  0.625  0.000105  0.000000  0.000005   \n",
       "106343  1.166667e-07  0.477273  0.000000  0.375  0.000105  0.000000  0.000014   \n",
       "130089  1.500000e-07  0.363636  0.000000  0.375  0.000105  0.000000  0.000014   \n",
       "231026  1.722326e-02  0.856061  0.416667  0.250  0.001159  0.001640  0.000124   \n",
       "147844  5.000001e-08  0.901515  0.166667  0.375  0.000105  0.000000  0.000007   \n",
       "58003   5.990434e-03  0.856061  0.000000  0.250  0.005795  0.001093  0.005329   \n",
       "\n",
       "          dbytes      rate      sttl  ...  ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "83703   0.000018  0.000037  0.996078  ...        0.00              0.00   \n",
       "215281  0.000018  0.000061  0.996078  ...        0.02              0.02   \n",
       "66227   0.000052  0.000032  0.996078  ...        0.02              0.02   \n",
       "104554  0.000055  0.000026  0.996078  ...        0.00              0.00   \n",
       "92327   0.000000  0.125000  0.996078  ...        0.02              0.00   \n",
       "106343  0.000000  0.142857  0.996078  ...        0.00              0.00   \n",
       "130089  0.000000  0.111111  0.996078  ...        0.04              0.04   \n",
       "231026  0.000694  0.000028  0.121569  ...        0.04              0.00   \n",
       "147844  0.000000  0.333333  0.996078  ...        0.26              0.26   \n",
       "58003   0.000036  0.000186  0.996078  ...        0.00              0.00   \n",
       "\n",
       "        ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "83703           0.000000        0.000000           0.0         0.0   \n",
       "215281          0.000000        0.093750           0.0         0.0   \n",
       "66227           0.000000        0.031250           0.0         0.0   \n",
       "104554          0.000000        0.000000           0.0         0.0   \n",
       "92327           0.000000        0.109375           0.0         0.0   \n",
       "106343          0.000000        0.031250           0.0         0.0   \n",
       "130089          0.044444        0.078125           0.0         0.0   \n",
       "231026          0.000000        0.031250           0.0         0.0   \n",
       "147844          0.288889        0.406250           0.0         0.0   \n",
       "58003           0.000000        0.000000           0.0         0.0   \n",
       "\n",
       "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \n",
       "83703           0.000000        0.00    0.000000              0.0  \n",
       "215281          0.000000        0.04    0.098361              0.0  \n",
       "66227           0.000000        0.38    0.032787              0.0  \n",
       "104554          0.000000        0.00    0.000000              0.0  \n",
       "92327           0.000000        0.02    0.114754              0.0  \n",
       "106343          0.000000        0.00    0.032787              0.0  \n",
       "130089          0.000000        0.06    0.081967              0.0  \n",
       "231026          0.033333        0.02    0.016393              0.0  \n",
       "147844          0.000000        0.26    0.426230              0.0  \n",
       "58003           0.000000        0.04    0.000000              0.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = df_test.drop(['id', 'label', 'attack_cat2','attack_cat_Analysis','attack_cat_Backdoor','attack_cat_DoS','attack_cat_Exploits','attack_cat_Fuzzers','attack_cat_Generic','attack_cat_Normal','attack_cat_Reconnaissance','attack_cat_Shellcode','attack_cat_Worms'], axis=1)\n",
    "\n",
    "analysis_test = df_test.iloc[:,-10]\n",
    "backdoor_test = df_test.iloc[:,-9]\n",
    "dos_test = df_test.iloc[:,-8]\n",
    "exploits_test = df_test.iloc[:,-7]\n",
    "fuzzers_test = df_test.iloc[:,-6]\n",
    "generic_test = df_test.iloc[:,-5]\n",
    "normal_test = df_test.iloc[:,-4]\n",
    "reconnaissance_test = df_test.iloc[:,-3]\n",
    "shellcode_test = df_test.iloc[:,-2]\n",
    "worms_test = df_test.iloc[:,-1]\n",
    "\n",
    "attack_test = df_test.iloc[:,-11]\n",
    "\n",
    "#min-max scaling\n",
    "testdata_norm = (testdata - testdata.min()) / (testdata.max() - testdata.min())\n",
    "testdata_norm = testdata_norm.fillna(0)\n",
    "\n",
    "testdata_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8613787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_X = torch.tensor(testdata_norm.values, dtype=torch.float32)\n",
    "#test_Y = torch.tensor(testlabel.values, dtype=torch.long) \n",
    "\n",
    "#test = TensorDataset(test_X, test_Y)\n",
    "#test_loader = DataLoader(test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e08eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing 10 types of binary classification set\n",
    "test_X = torch.tensor(testdata_norm.values, dtype=torch.float32)\n",
    "\n",
    "test_analysis_Y = torch.tensor(analysis_test.values, dtype=torch.long) \n",
    "test_backdoor_Y = torch.tensor(backdoor_test.values, dtype=torch.long) \n",
    "test_dos_Y = torch.tensor(dos_test.values, dtype=torch.long) \n",
    "test_exploits_Y = torch.tensor(exploits_test.values, dtype=torch.long) \n",
    "test_fuzzers_Y = torch.tensor(fuzzers_test.values, dtype=torch.long) \n",
    "test_generic_Y = torch.tensor(generic_test.values, dtype=torch.long) \n",
    "test_normal_Y = torch.tensor(normal_test.values, dtype=torch.long) \n",
    "test_reconnaissance_Y = torch.tensor(reconnaissance_test.values, dtype=torch.long) \n",
    "test_shellcode_Y = torch.tensor(shellcode_test.values, dtype=torch.long) \n",
    "test_worms_Y = torch.tensor(worms_test.values, dtype=torch.long) \n",
    "\n",
    "test_analysis = TensorDataset(test_X, test_analysis_Y)\n",
    "test_backdoor = TensorDataset(test_X, test_backdoor_Y)\n",
    "test_dos = TensorDataset(test_X, test_dos_Y)\n",
    "test_exploits = TensorDataset(test_X, test_exploits_Y)\n",
    "test_fuzzers = TensorDataset(test_X, test_fuzzers_Y)\n",
    "test_generic = TensorDataset(test_X, test_generic_Y)\n",
    "test_normal = TensorDataset(test_X, test_normal_Y)\n",
    "test_reconnaissance = TensorDataset(test_X, test_reconnaissance_Y)\n",
    "test_shellcode = TensorDataset(test_X, test_shellcode_Y)\n",
    "test_worms = TensorDataset(test_X, test_worms_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad39c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_analysis_loader = DataLoader(test_analysis, batch_size=100, shuffle=True)\n",
    "test_backdoor_loader = DataLoader(test_backdoor, batch_size=100, shuffle=True)\n",
    "test_dos_loader = DataLoader(test_dos, batch_size=100, shuffle=True)\n",
    "test_exploits_loader = DataLoader(test_exploits, batch_size=100, shuffle=True)\n",
    "test_fuzzers_loader = DataLoader(test_fuzzers, batch_size=100, shuffle=True)\n",
    "test_generic_loader = DataLoader(test_generic, batch_size=100, shuffle=True)\n",
    "test_normal_loader = DataLoader(test_normal, batch_size=100, shuffle=True)\n",
    "test_reconnaissance_loader = DataLoader(test_reconnaissance, batch_size=100, shuffle=True)\n",
    "test_shellcode_loader = DataLoader(test_shellcode, batch_size=100, shuffle=True)\n",
    "test_worms_loader = DataLoader(test_worms, batch_size=100, shuffle=True)\n",
    "# drop_last = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e98d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 71042/71605 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_analysis.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_analysis_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_analysis = model_analysis(test_x)\n",
    "    pred = torch.max(output_test_analysis.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca8d389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred\n",
       "0   4.057994e-06\n",
       "1   5.228340e-13\n",
       "2   1.064407e-12\n",
       "3   8.059102e-10\n",
       "4   5.029461e-04\n",
       "5   4.804679e-02\n",
       "6   4.804679e-02\n",
       "7   9.361324e-24\n",
       "8   9.168352e-11\n",
       "9   1.819869e-19"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data = pd.DataFrame()\n",
    "twoS_test_data[\"analysis_pred\"]=output_test_analysis.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a190ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for backdoor\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_backdoor.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_backdoor_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_backdoor.zero_grad()\n",
    "        output = model_backdoor(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_backdoor.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_backdoor_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52289fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 165869/167077 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_backdoor.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_backdoor_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_backdoor = model_backdoor(train_x)\n",
    "    pred = torch.max(output_backdoor.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67ded02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.733373e-29</td>\n",
       "      <td>6.250578e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435122e-08</td>\n",
       "      <td>1.821575e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950863e-20</td>\n",
       "      <td>1.338373e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090117e-15</td>\n",
       "      <td>5.022311e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.157892e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.733348e-22</td>\n",
       "      <td>2.729735e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.574244e-08</td>\n",
       "      <td>3.809537e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.273745e-03</td>\n",
       "      <td>3.018818e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred\n",
       "0   5.733373e-29   6.250578e-19\n",
       "1   3.435122e-08   1.821575e-21\n",
       "2   5.950863e-20   1.338373e-22\n",
       "3   1.090117e-15   5.022311e-18\n",
       "4   4.804679e-02   3.599505e-02\n",
       "5   4.157892e-20   0.000000e+00\n",
       "6   4.804679e-02   3.599505e-02\n",
       "7   8.733348e-22   2.729735e-21\n",
       "8   1.574244e-08   3.809537e-18\n",
       "9   6.273745e-03   3.018818e-04"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"backdoor_pred\"]=output_backdoor.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fca65d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 71088/71605 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_backdoor.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_backdoor_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_backdoor = model_backdoor(test_x)\n",
    "    pred = torch.max(output_test_backdoor.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfa8cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred\n",
       "0   4.057994e-06   2.584545e-03\n",
       "1   5.228340e-13   6.202563e-15\n",
       "2   1.064407e-12   2.141497e-05\n",
       "3   8.059102e-10   3.021023e-04\n",
       "4   5.029461e-04   1.365519e-08\n",
       "5   4.804679e-02   3.599505e-02\n",
       "6   4.804679e-02   3.599505e-02\n",
       "7   9.361324e-24   1.718545e-13\n",
       "8   9.168352e-11   1.767525e-15\n",
       "9   1.819869e-19   1.369630e-23"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"backdoor_pred\"]=output_test_backdoor.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7517a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for dos\n",
    "batch_loss_list=[]\n",
    "for epoch in range(100): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_dos.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_dos_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_dos.zero_grad()\n",
    "        output = model_dos(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_dos.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_dos_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c412b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 158461/167077 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_dos.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_dos_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_dos = model_dos(train_x)\n",
    "    pred = torch.max(output_dos.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "123f88a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.733373e-29</td>\n",
       "      <td>6.250578e-19</td>\n",
       "      <td>7.539402e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435122e-08</td>\n",
       "      <td>1.821575e-21</td>\n",
       "      <td>7.750936e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950863e-20</td>\n",
       "      <td>1.338373e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090117e-15</td>\n",
       "      <td>5.022311e-18</td>\n",
       "      <td>5.495129e-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.157892e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.484529e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.733348e-22</td>\n",
       "      <td>2.729735e-21</td>\n",
       "      <td>1.214563e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.574244e-08</td>\n",
       "      <td>3.809537e-18</td>\n",
       "      <td>2.147255e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.273745e-03</td>\n",
       "      <td>3.018818e-04</td>\n",
       "      <td>3.213531e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred\n",
       "0   5.733373e-29   6.250578e-19  7.539402e-35\n",
       "1   3.435122e-08   1.821575e-21  7.750936e-11\n",
       "2   5.950863e-20   1.338373e-22  0.000000e+00\n",
       "3   1.090117e-15   5.022311e-18  5.495129e-36\n",
       "4   4.804679e-02   3.599505e-02  3.213531e-01\n",
       "5   4.157892e-20   0.000000e+00  3.484529e-15\n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01\n",
       "7   8.733348e-22   2.729735e-21  1.214563e-09\n",
       "8   1.574244e-08   3.809537e-18  2.147255e-16\n",
       "9   6.273745e-03   3.018818e-04  3.213531e-01"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"dos_pred\"]=output_dos.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62ce3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 67957/71605 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_dos.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_dos_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_dos = model_dos(test_x)\n",
    "    pred = torch.max(output_test_dos.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1d7e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02\n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04\n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02\n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02\n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19\n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01\n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01\n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00\n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13\n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"dos_pred\"]=output_test_dos.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eeb8aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model for exploits\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_exploits.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_exploits_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_exploits.zero_grad()\n",
    "        output = model_exploits(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_exploits.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_exploits_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47752fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 153818/167077 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_exploits.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_exploits_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_exploits = model_exploits(train_x)\n",
    "    pred = torch.max(output_exploits.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbaf267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.733373e-29</td>\n",
       "      <td>6.250578e-19</td>\n",
       "      <td>7.539402e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435122e-08</td>\n",
       "      <td>1.821575e-21</td>\n",
       "      <td>7.750936e-11</td>\n",
       "      <td>4.420427e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950863e-20</td>\n",
       "      <td>1.338373e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.437731e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090117e-15</td>\n",
       "      <td>5.022311e-18</td>\n",
       "      <td>5.495129e-36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.157892e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.484529e-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.733348e-22</td>\n",
       "      <td>2.729735e-21</td>\n",
       "      <td>1.214563e-09</td>\n",
       "      <td>1.911803e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.574244e-08</td>\n",
       "      <td>3.809537e-18</td>\n",
       "      <td>2.147255e-16</td>\n",
       "      <td>9.956461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.273745e-03</td>\n",
       "      <td>3.018818e-04</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.512513e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred\n",
       "0   5.733373e-29   6.250578e-19  7.539402e-35   0.000000e+00\n",
       "1   3.435122e-08   1.821575e-21  7.750936e-11   4.420427e-07\n",
       "2   5.950863e-20   1.338373e-22  0.000000e+00   9.437731e-40\n",
       "3   1.090117e-15   5.022311e-18  5.495129e-36   0.000000e+00\n",
       "4   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01\n",
       "5   4.157892e-20   0.000000e+00  3.484529e-15   0.000000e+00\n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01\n",
       "7   8.733348e-22   2.729735e-21  1.214563e-09   1.911803e-05\n",
       "8   1.574244e-08   3.809537e-18  2.147255e-16   9.956461e-01\n",
       "9   6.273745e-03   3.018818e-04  3.213531e-01   4.512513e-01"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data[\"exploits_pred\"]=output_exploits.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5100806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 1], device='cuda:0')\n",
      "correct _rate: 65696/71605 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_exploits.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_exploits_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_exploits = model_exploits(test_x)\n",
    "    pred = torch.max(output_test_exploits.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "471b6adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01\n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04\n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03\n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02\n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10\n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01\n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01\n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45\n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07\n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data[\"exploits_pred\"]=output_test_exploits.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ed1987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 158263/167077 (95%)\n",
      "\n",
      "tensor([0, 0, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 67633/71605 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03\n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01\n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01\n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01\n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04\n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02\n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02\n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05\n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17\n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for fuzzers\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_fuzzers.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_fuzzers_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_fuzzers.zero_grad()\n",
    "        output = model_fuzzers(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_fuzzers.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_fuzzers_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_fuzzers.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_fuzzers_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_fuzzers = model_fuzzers(train_x)\n",
    "    pred = torch.max(output_fuzzers.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"fuzzers_pred\"]=output_fuzzers.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_fuzzers.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_fuzzers_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_fuzzers = model_fuzzers(test_x)\n",
    "    pred = torch.max(output_test_fuzzers.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"fuzzers_pred\"]=output_test_fuzzers.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f8c77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 166459/167077 (100%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "correct _rate: 71318/71605 (100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred  \n",
       "0  3.291132e-03  \n",
       "1  4.235936e-05  \n",
       "2  1.045906e-04  \n",
       "3  5.815274e-03  \n",
       "4  3.300777e-06  \n",
       "5  1.451284e-02  \n",
       "6  1.697282e-02  \n",
       "7  1.570003e-13  \n",
       "8  1.000000e+00  \n",
       "9  1.821588e-03  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for generic\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_generic.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_generic_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_generic.zero_grad()\n",
    "        output = model_generic(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_generic.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_generic_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_generic.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_generic_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_generic = model_generic(train_x)\n",
    "    pred = torch.max(output_generic.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"generic_pred\"]=output_generic.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_generic.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_generic_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_generic = model_generic(test_x)\n",
    "    pred = torch.max(output_test_generic.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"generic_pred\"]=output_test_generic.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b2c1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 159847/167077 (96%)\n",
      "\n",
      "tensor([0, 1, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 68105/71605 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "      <td>5.412919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "      <td>6.473816e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "      <td>1.353174e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "      <td>2.152032e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "      <td>7.348389e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "      <td>9.834062e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.787194e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "      <td>1.843715e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred   normal_pred  \n",
       "0  3.291132e-03  5.412919e-03  \n",
       "1  4.235936e-05  6.473816e-01  \n",
       "2  1.045906e-04  1.353174e-02  \n",
       "3  5.815274e-03  2.152032e-01  \n",
       "4  3.300777e-06  1.000000e+00  \n",
       "5  1.451284e-02  7.348389e-06  \n",
       "6  1.697282e-02  9.834062e-08  \n",
       "7  1.570003e-13  1.000000e+00  \n",
       "8  1.000000e+00  1.787194e-07  \n",
       "9  1.821588e-03  1.843715e-02  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for normal\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_normal.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_normal_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_normal.zero_grad()\n",
    "        output = model_normal(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_normal.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_normal_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_normal.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_normal_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_normal = model_normal(train_x)\n",
    "    pred = torch.max(output_normal.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"normal_pred\"]=output_normal.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_normal.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_normal_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_normal = model_normal(test_x)\n",
    "    pred = torch.max(output_test_normal.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"normal_pred\"]=output_test_normal.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5ab6c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 163690/167077 (98%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 70305/71605 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "      <td>5.412919e-03</td>\n",
       "      <td>4.725392e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "      <td>6.473816e-01</td>\n",
       "      <td>3.307960e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "      <td>1.353174e-02</td>\n",
       "      <td>2.080167e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "      <td>2.152032e-01</td>\n",
       "      <td>9.135199e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.574951e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "      <td>7.348389e-06</td>\n",
       "      <td>4.821298e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "      <td>9.834062e-08</td>\n",
       "      <td>4.678237e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.245482e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.787194e-07</td>\n",
       "      <td>6.328558e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "      <td>1.843715e-02</td>\n",
       "      <td>4.203895e-45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  \n",
       "0  3.291132e-03  5.412919e-03         4.725392e-01  \n",
       "1  4.235936e-05  6.473816e-01         3.307960e-14  \n",
       "2  1.045906e-04  1.353174e-02         2.080167e-05  \n",
       "3  5.815274e-03  2.152032e-01         9.135199e-05  \n",
       "4  3.300777e-06  1.000000e+00         4.574951e-14  \n",
       "5  1.451284e-02  7.348389e-06         4.821298e-02  \n",
       "6  1.697282e-02  9.834062e-08         4.678237e-02  \n",
       "7  1.570003e-13  1.000000e+00         2.245482e-11  \n",
       "8  1.000000e+00  1.787194e-07         6.328558e-10  \n",
       "9  1.821588e-03  1.843715e-02         4.203895e-45  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for reconnaissance\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_reconnaissance.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_reconnaissance_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_reconnaissance.zero_grad()\n",
    "        output = model_reconnaissance(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_reconnaissance.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_reconnaissance_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_reconnaissance.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_reconnaissance_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_reconnaissance = model_reconnaissance(train_x)\n",
    "    pred = torch.max(output_reconnaissance.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"reconnaissance_pred\"]=output_reconnaissance.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_reconnaissance.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_reconnaissance_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_reconnaissance = model_reconnaissance(test_x)\n",
    "    pred = torch.max(output_test_reconnaissance.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"reconnaissance_pred\"]=output_test_reconnaissance.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b68eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 166384/167077 (100%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 71303/71605 (100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "      <td>5.412919e-03</td>\n",
       "      <td>4.725392e-01</td>\n",
       "      <td>1.058855e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "      <td>6.473816e-01</td>\n",
       "      <td>3.307960e-14</td>\n",
       "      <td>7.301754e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "      <td>1.353174e-02</td>\n",
       "      <td>2.080167e-05</td>\n",
       "      <td>4.162353e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "      <td>2.152032e-01</td>\n",
       "      <td>9.135199e-05</td>\n",
       "      <td>2.425542e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.574951e-14</td>\n",
       "      <td>5.839519e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "      <td>7.348389e-06</td>\n",
       "      <td>4.821298e-02</td>\n",
       "      <td>1.694935e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "      <td>9.834062e-08</td>\n",
       "      <td>4.678237e-02</td>\n",
       "      <td>1.526151e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.245482e-11</td>\n",
       "      <td>4.216239e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.787194e-07</td>\n",
       "      <td>6.328558e-10</td>\n",
       "      <td>1.087341e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "      <td>1.843715e-02</td>\n",
       "      <td>4.203895e-45</td>\n",
       "      <td>9.890521e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \n",
       "0  3.291132e-03  5.412919e-03         4.725392e-01    1.058855e-07  \n",
       "1  4.235936e-05  6.473816e-01         3.307960e-14    7.301754e-06  \n",
       "2  1.045906e-04  1.353174e-02         2.080167e-05    4.162353e-08  \n",
       "3  5.815274e-03  2.152032e-01         9.135199e-05    2.425542e-03  \n",
       "4  3.300777e-06  1.000000e+00         4.574951e-14    5.839519e-15  \n",
       "5  1.451284e-02  7.348389e-06         4.821298e-02    1.694935e-16  \n",
       "6  1.697282e-02  9.834062e-08         4.678237e-02    1.526151e-22  \n",
       "7  1.570003e-13  1.000000e+00         2.245482e-11    4.216239e-12  \n",
       "8  1.000000e+00  1.787194e-07         6.328558e-10    1.087341e-24  \n",
       "9  1.821588e-03  1.843715e-02         4.203895e-45    9.890521e-14  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for shellcode\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_shellcode.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_shellcode_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_shellcode.zero_grad()\n",
    "        output = model_shellcode(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_shellcode.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_shellcode_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_shellcode.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_shellcode_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_shellcode = model_shellcode(train_x)\n",
    "    pred = torch.max(output_shellcode.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"shellcode_pred\"]=output_shellcode.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_shellcode.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_shellcode_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_shellcode = model_shellcode(test_x)\n",
    "    pred = torch.max(output_test_shellcode.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"shellcode_pred\"]=output_test_shellcode.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "819ee0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 166999/167077 (100%)\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "correct _rate: 71564/71605 (100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "      <td>5.412919e-03</td>\n",
       "      <td>4.725392e-01</td>\n",
       "      <td>1.058855e-07</td>\n",
       "      <td>9.706838e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "      <td>6.473816e-01</td>\n",
       "      <td>3.307960e-14</td>\n",
       "      <td>7.301754e-06</td>\n",
       "      <td>1.349035e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "      <td>1.353174e-02</td>\n",
       "      <td>2.080167e-05</td>\n",
       "      <td>4.162353e-08</td>\n",
       "      <td>9.189757e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "      <td>2.152032e-01</td>\n",
       "      <td>9.135199e-05</td>\n",
       "      <td>2.425542e-03</td>\n",
       "      <td>6.104952e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.574951e-14</td>\n",
       "      <td>5.839519e-15</td>\n",
       "      <td>4.796616e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "      <td>7.348389e-06</td>\n",
       "      <td>4.821298e-02</td>\n",
       "      <td>1.694935e-16</td>\n",
       "      <td>1.873232e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "      <td>9.834062e-08</td>\n",
       "      <td>4.678237e-02</td>\n",
       "      <td>1.526151e-22</td>\n",
       "      <td>1.688455e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.245482e-11</td>\n",
       "      <td>4.216239e-12</td>\n",
       "      <td>4.728580e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.787194e-07</td>\n",
       "      <td>6.328558e-10</td>\n",
       "      <td>1.087341e-24</td>\n",
       "      <td>2.833992e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "      <td>1.843715e-02</td>\n",
       "      <td>4.203895e-45</td>\n",
       "      <td>9.890521e-14</td>\n",
       "      <td>6.219158e-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  3.291132e-03  5.412919e-03         4.725392e-01    1.058855e-07   \n",
       "1  4.235936e-05  6.473816e-01         3.307960e-14    7.301754e-06   \n",
       "2  1.045906e-04  1.353174e-02         2.080167e-05    4.162353e-08   \n",
       "3  5.815274e-03  2.152032e-01         9.135199e-05    2.425542e-03   \n",
       "4  3.300777e-06  1.000000e+00         4.574951e-14    5.839519e-15   \n",
       "5  1.451284e-02  7.348389e-06         4.821298e-02    1.694935e-16   \n",
       "6  1.697282e-02  9.834062e-08         4.678237e-02    1.526151e-22   \n",
       "7  1.570003e-13  1.000000e+00         2.245482e-11    4.216239e-12   \n",
       "8  1.000000e+00  1.787194e-07         6.328558e-10    1.087341e-24   \n",
       "9  1.821588e-03  1.843715e-02         4.203895e-45    9.890521e-14   \n",
       "\n",
       "     worms_pred  \n",
       "0  9.706838e-05  \n",
       "1  1.349035e-22  \n",
       "2  9.189757e-16  \n",
       "3  6.104952e-24  \n",
       "4  4.796616e-20  \n",
       "5  1.873232e-10  \n",
       "6  1.688455e-10  \n",
       "7  4.728580e-19  \n",
       "8  2.833992e-09  \n",
       "9  6.219158e-27  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the machine learning model for worms\n",
    "batch_loss_list=[]\n",
    "for epoch in range(300): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model_worms.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_worms_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer_worms.zero_grad()\n",
    "        output = model_worms(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer_worms.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_worms_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_worms.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_worms_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output_worms = model_worms(train_x)\n",
    "    pred = torch.max(output_worms.data, 1)[1]\n",
    "    #print(output.data.softmax(dim=1))\n",
    "    #print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_train_data[\"worms_pred\"]=output_worms.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_train_data.head(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model_worms.eval()\n",
    "    test_x, test_y = Variable(test_X), Variable(test_worms_Y)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    output_test_worms = model_worms(test_x)\n",
    "    pred = torch.max(output_test_worms.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "twoS_test_data[\"worms_pred\"]=output_test_worms.data.softmax(dim=1)[:,1].to('cpu').detach().numpy().tolist()\n",
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d92cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.fc4 = nn.Linear(100, 10)\n",
    "        self.bc1 = nn.BatchNorm1d(100)\n",
    "        self.bc2 = nn.BatchNorm1d(100)\n",
    "        self.bc3 = nn.BatchNorm1d(100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bc1(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bc2(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bc3(x)\n",
    "        x = F.relu(x) # ReLU: max(x, 0)\n",
    "        x = self.fc4(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model2 = Net2()\n",
    "\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24ea048d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.733373e-29</td>\n",
       "      <td>6.250578e-19</td>\n",
       "      <td>7.539402e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.836076e-09</td>\n",
       "      <td>6.265219e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.535022e-15</td>\n",
       "      <td>1.055001e-11</td>\n",
       "      <td>1.903452e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.435122e-08</td>\n",
       "      <td>1.821575e-21</td>\n",
       "      <td>7.750936e-11</td>\n",
       "      <td>4.420427e-07</td>\n",
       "      <td>3.416356e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.437381e-07</td>\n",
       "      <td>3.161641e-10</td>\n",
       "      <td>5.658384e-24</td>\n",
       "      <td>1.183567e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.950863e-20</td>\n",
       "      <td>1.338373e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.437731e-40</td>\n",
       "      <td>7.522134e-06</td>\n",
       "      <td>4.246021e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.846251e-20</td>\n",
       "      <td>1.665157e-06</td>\n",
       "      <td>3.350487e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090117e-15</td>\n",
       "      <td>5.022311e-18</td>\n",
       "      <td>5.495129e-36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.439204e-09</td>\n",
       "      <td>4.752686e-07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.447636e-22</td>\n",
       "      <td>1.012230e-11</td>\n",
       "      <td>4.629980e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.566233e-02</td>\n",
       "      <td>3.598570e-02</td>\n",
       "      <td>5.581888e-05</td>\n",
       "      <td>3.442169e-02</td>\n",
       "      <td>4.716759e-04</td>\n",
       "      <td>1.078856e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.157892e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.484529e-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.810762e-10</td>\n",
       "      <td>2.856784e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.648569e-09</td>\n",
       "      <td>7.722195e-21</td>\n",
       "      <td>4.764071e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.101146e-02</td>\n",
       "      <td>1.938453e-02</td>\n",
       "      <td>1.099220e-08</td>\n",
       "      <td>4.821261e-02</td>\n",
       "      <td>4.843993e-07</td>\n",
       "      <td>1.722881e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.733348e-22</td>\n",
       "      <td>2.729735e-21</td>\n",
       "      <td>1.214563e-09</td>\n",
       "      <td>1.911803e-05</td>\n",
       "      <td>4.861691e-07</td>\n",
       "      <td>2.195050e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.820286e-24</td>\n",
       "      <td>1.948054e-10</td>\n",
       "      <td>8.908855e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.574244e-08</td>\n",
       "      <td>3.809537e-18</td>\n",
       "      <td>2.147255e-16</td>\n",
       "      <td>9.956461e-01</td>\n",
       "      <td>6.812713e-07</td>\n",
       "      <td>5.220345e-06</td>\n",
       "      <td>1.178547e-04</td>\n",
       "      <td>2.898806e-18</td>\n",
       "      <td>3.880724e-08</td>\n",
       "      <td>1.139231e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.273745e-03</td>\n",
       "      <td>3.018818e-04</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.512513e-01</td>\n",
       "      <td>4.336499e-04</td>\n",
       "      <td>1.220824e-03</td>\n",
       "      <td>1.554651e-02</td>\n",
       "      <td>1.791653e-03</td>\n",
       "      <td>3.020374e-08</td>\n",
       "      <td>2.805670e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   5.733373e-29   6.250578e-19  7.539402e-35   0.000000e+00  1.836076e-09   \n",
       "1   3.435122e-08   1.821575e-21  7.750936e-11   4.420427e-07  3.416356e-19   \n",
       "2   5.950863e-20   1.338373e-22  0.000000e+00   9.437731e-40  7.522134e-06   \n",
       "3   1.090117e-15   5.022311e-18  5.495129e-36   0.000000e+00  8.439204e-09   \n",
       "4   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.566233e-02   \n",
       "5   4.157892e-20   0.000000e+00  3.484529e-15   0.000000e+00  2.810762e-10   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.101146e-02   \n",
       "7   8.733348e-22   2.729735e-21  1.214563e-09   1.911803e-05  4.861691e-07   \n",
       "8   1.574244e-08   3.809537e-18  2.147255e-16   9.956461e-01  6.812713e-07   \n",
       "9   6.273745e-03   3.018818e-04  3.213531e-01   4.512513e-01  4.336499e-04   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  6.265219e-09  1.000000e+00         7.535022e-15    1.055001e-11   \n",
       "1  1.000000e+00  4.437381e-07         3.161641e-10    5.658384e-24   \n",
       "2  4.246021e-18  1.000000e+00         2.846251e-20    1.665157e-06   \n",
       "3  4.752686e-07  1.000000e+00         2.447636e-22    1.012230e-11   \n",
       "4  3.598570e-02  5.581888e-05         3.442169e-02    4.716759e-04   \n",
       "5  2.856784e-10  1.000000e+00         1.648569e-09    7.722195e-21   \n",
       "6  1.938453e-02  1.099220e-08         4.821261e-02    4.843993e-07   \n",
       "7  2.195050e-05  1.000000e+00         4.820286e-24    1.948054e-10   \n",
       "8  5.220345e-06  1.178547e-04         2.898806e-18    3.880724e-08   \n",
       "9  1.220824e-03  1.554651e-02         1.791653e-03    3.020374e-08   \n",
       "\n",
       "     worms_pred  \n",
       "0  1.903452e-23  \n",
       "1  1.183567e-09  \n",
       "2  3.350487e-09  \n",
       "3  4.629980e-19  \n",
       "4  1.078856e-08  \n",
       "5  4.764071e-25  \n",
       "6  1.722881e-09  \n",
       "7  8.908855e-38  \n",
       "8  1.139231e-34  \n",
       "9  2.805670e-16  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37332c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_pred</th>\n",
       "      <th>backdoor_pred</th>\n",
       "      <th>dos_pred</th>\n",
       "      <th>exploits_pred</th>\n",
       "      <th>fuzzers_pred</th>\n",
       "      <th>generic_pred</th>\n",
       "      <th>normal_pred</th>\n",
       "      <th>reconnaissance_pred</th>\n",
       "      <th>shellcode_pred</th>\n",
       "      <th>worms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.057994e-06</td>\n",
       "      <td>2.584545e-03</td>\n",
       "      <td>2.724890e-02</td>\n",
       "      <td>4.544270e-01</td>\n",
       "      <td>1.593328e-03</td>\n",
       "      <td>3.291132e-03</td>\n",
       "      <td>5.412919e-03</td>\n",
       "      <td>4.725392e-01</td>\n",
       "      <td>1.058855e-07</td>\n",
       "      <td>9.706838e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.228340e-13</td>\n",
       "      <td>6.202563e-15</td>\n",
       "      <td>2.611580e-04</td>\n",
       "      <td>6.026404e-04</td>\n",
       "      <td>2.315588e-01</td>\n",
       "      <td>4.235936e-05</td>\n",
       "      <td>6.473816e-01</td>\n",
       "      <td>3.307960e-14</td>\n",
       "      <td>7.301754e-06</td>\n",
       "      <td>1.349035e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064407e-12</td>\n",
       "      <td>2.141497e-05</td>\n",
       "      <td>1.656191e-02</td>\n",
       "      <td>3.367888e-03</td>\n",
       "      <td>9.043506e-01</td>\n",
       "      <td>1.045906e-04</td>\n",
       "      <td>1.353174e-02</td>\n",
       "      <td>2.080167e-05</td>\n",
       "      <td>4.162353e-08</td>\n",
       "      <td>9.189757e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.059102e-10</td>\n",
       "      <td>3.021023e-04</td>\n",
       "      <td>6.442982e-02</td>\n",
       "      <td>2.589165e-02</td>\n",
       "      <td>8.119604e-01</td>\n",
       "      <td>5.815274e-03</td>\n",
       "      <td>2.152032e-01</td>\n",
       "      <td>9.135199e-05</td>\n",
       "      <td>2.425542e-03</td>\n",
       "      <td>6.104952e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.029461e-04</td>\n",
       "      <td>1.365519e-08</td>\n",
       "      <td>1.661922e-19</td>\n",
       "      <td>5.561249e-10</td>\n",
       "      <td>9.958537e-04</td>\n",
       "      <td>3.300777e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.574951e-14</td>\n",
       "      <td>5.839519e-15</td>\n",
       "      <td>4.796616e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>4.245339e-02</td>\n",
       "      <td>1.451284e-02</td>\n",
       "      <td>7.348389e-06</td>\n",
       "      <td>4.821298e-02</td>\n",
       "      <td>1.694935e-16</td>\n",
       "      <td>1.873232e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.804679e-02</td>\n",
       "      <td>3.599505e-02</td>\n",
       "      <td>3.213531e-01</td>\n",
       "      <td>4.006477e-01</td>\n",
       "      <td>3.993946e-02</td>\n",
       "      <td>1.697282e-02</td>\n",
       "      <td>9.834062e-08</td>\n",
       "      <td>4.678237e-02</td>\n",
       "      <td>1.526151e-22</td>\n",
       "      <td>1.688455e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.361324e-24</td>\n",
       "      <td>1.718545e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401298e-45</td>\n",
       "      <td>5.523873e-05</td>\n",
       "      <td>1.570003e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.245482e-11</td>\n",
       "      <td>4.216239e-12</td>\n",
       "      <td>4.728580e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.168352e-11</td>\n",
       "      <td>1.767525e-15</td>\n",
       "      <td>7.814356e-13</td>\n",
       "      <td>2.386280e-07</td>\n",
       "      <td>1.229546e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.787194e-07</td>\n",
       "      <td>6.328558e-10</td>\n",
       "      <td>1.087341e-24</td>\n",
       "      <td>2.833992e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.819869e-19</td>\n",
       "      <td>1.369630e-23</td>\n",
       "      <td>4.754138e-02</td>\n",
       "      <td>7.808670e-01</td>\n",
       "      <td>7.256886e-02</td>\n",
       "      <td>1.821588e-03</td>\n",
       "      <td>1.843715e-02</td>\n",
       "      <td>4.203895e-45</td>\n",
       "      <td>9.890521e-14</td>\n",
       "      <td>6.219158e-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_pred  backdoor_pred      dos_pred  exploits_pred  fuzzers_pred  \\\n",
       "0   4.057994e-06   2.584545e-03  2.724890e-02   4.544270e-01  1.593328e-03   \n",
       "1   5.228340e-13   6.202563e-15  2.611580e-04   6.026404e-04  2.315588e-01   \n",
       "2   1.064407e-12   2.141497e-05  1.656191e-02   3.367888e-03  9.043506e-01   \n",
       "3   8.059102e-10   3.021023e-04  6.442982e-02   2.589165e-02  8.119604e-01   \n",
       "4   5.029461e-04   1.365519e-08  1.661922e-19   5.561249e-10  9.958537e-04   \n",
       "5   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  4.245339e-02   \n",
       "6   4.804679e-02   3.599505e-02  3.213531e-01   4.006477e-01  3.993946e-02   \n",
       "7   9.361324e-24   1.718545e-13  0.000000e+00   1.401298e-45  5.523873e-05   \n",
       "8   9.168352e-11   1.767525e-15  7.814356e-13   2.386280e-07  1.229546e-17   \n",
       "9   1.819869e-19   1.369630e-23  4.754138e-02   7.808670e-01  7.256886e-02   \n",
       "\n",
       "   generic_pred   normal_pred  reconnaissance_pred  shellcode_pred  \\\n",
       "0  3.291132e-03  5.412919e-03         4.725392e-01    1.058855e-07   \n",
       "1  4.235936e-05  6.473816e-01         3.307960e-14    7.301754e-06   \n",
       "2  1.045906e-04  1.353174e-02         2.080167e-05    4.162353e-08   \n",
       "3  5.815274e-03  2.152032e-01         9.135199e-05    2.425542e-03   \n",
       "4  3.300777e-06  1.000000e+00         4.574951e-14    5.839519e-15   \n",
       "5  1.451284e-02  7.348389e-06         4.821298e-02    1.694935e-16   \n",
       "6  1.697282e-02  9.834062e-08         4.678237e-02    1.526151e-22   \n",
       "7  1.570003e-13  1.000000e+00         2.245482e-11    4.216239e-12   \n",
       "8  1.000000e+00  1.787194e-07         6.328558e-10    1.087341e-24   \n",
       "9  1.821588e-03  1.843715e-02         4.203895e-45    9.890521e-14   \n",
       "\n",
       "     worms_pred  \n",
       "0  9.706838e-05  \n",
       "1  1.349035e-22  \n",
       "2  9.189757e-16  \n",
       "3  6.104952e-24  \n",
       "4  4.796616e-20  \n",
       "5  1.873232e-10  \n",
       "6  1.688455e-10  \n",
       "7  4.728580e-19  \n",
       "8  2.833992e-09  \n",
       "9  6.219158e-27  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoS_test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "640f2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(twoS_train_data.values, dtype=torch.float32)\n",
    "train_Y = torch.tensor(attack_train.values, dtype=torch.long) \n",
    "train = TensorDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7cf0b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccd6ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the machine learning model\n",
    "batch_loss_list=[]\n",
    "for epoch in range(600): #learning 100 times\n",
    "    #total_loss = 0\n",
    "    model2.train()\n",
    "    loss_list=[]\n",
    "    for train_x, train_y in train_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        output = model2(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        loss_list.append(loss.data)\n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    batch_loss = sum(loss_list)/len(train_loader)\n",
    "    batch_loss_list.append(batch_loss.to('cpu').detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8fc5179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38173356652259827,\n",
       " 0.3641822338104248,\n",
       " 0.36038750410079956,\n",
       " 0.3582131862640381,\n",
       " 0.3560808002948761,\n",
       " 0.3544391989707947,\n",
       " 0.353730171918869,\n",
       " 0.35346731543540955,\n",
       " 0.35272014141082764,\n",
       " 0.351641446352005,\n",
       " 0.35103467106819153,\n",
       " 0.35045579075813293,\n",
       " 0.3501166105270386,\n",
       " 0.3497096598148346,\n",
       " 0.34994038939476013,\n",
       " 0.349591463804245,\n",
       " 0.3497408330440521,\n",
       " 0.34859389066696167,\n",
       " 0.3490772247314453,\n",
       " 0.348572313785553,\n",
       " 0.348207026720047,\n",
       " 0.3479268550872803,\n",
       " 0.3481791317462921,\n",
       " 0.3474534749984741,\n",
       " 0.34787628054618835,\n",
       " 0.3469572365283966,\n",
       " 0.3472856283187866,\n",
       " 0.34657981991767883,\n",
       " 0.346591979265213,\n",
       " 0.3465231657028198,\n",
       " 0.3468639850616455,\n",
       " 0.34681886434555054,\n",
       " 0.34589675068855286,\n",
       " 0.34595805406570435,\n",
       " 0.34598663449287415,\n",
       " 0.3451443612575531,\n",
       " 0.345685750246048,\n",
       " 0.3457096517086029,\n",
       " 0.34526026248931885,\n",
       " 0.34544047713279724,\n",
       " 0.3452375829219818,\n",
       " 0.3456973135471344,\n",
       " 0.34453046321868896,\n",
       " 0.3453456163406372,\n",
       " 0.3445844352245331,\n",
       " 0.34478339552879333,\n",
       " 0.34485483169555664,\n",
       " 0.34507957100868225,\n",
       " 0.34501874446868896,\n",
       " 0.34447476267814636,\n",
       " 0.34398573637008667,\n",
       " 0.34471648931503296,\n",
       " 0.34402111172676086,\n",
       " 0.3442656993865967,\n",
       " 0.34400248527526855,\n",
       " 0.34372687339782715,\n",
       " 0.3439585268497467,\n",
       " 0.3438035249710083,\n",
       " 0.3440571427345276,\n",
       " 0.3432822823524475,\n",
       " 0.34393754601478577,\n",
       " 0.34380096197128296,\n",
       " 0.34346020221710205,\n",
       " 0.3434472680091858,\n",
       " 0.3433721959590912,\n",
       " 0.3430267572402954,\n",
       " 0.3429558575153351,\n",
       " 0.34301403164863586,\n",
       " 0.3429560959339142,\n",
       " 0.3427301049232483,\n",
       " 0.34271830320358276,\n",
       " 0.3426261246204376,\n",
       " 0.3432370722293854,\n",
       " 0.34303227066993713,\n",
       " 0.34278109669685364,\n",
       " 0.342382550239563,\n",
       " 0.3425396680831909,\n",
       " 0.34273862838745117,\n",
       " 0.3422873616218567,\n",
       " 0.3426262140274048,\n",
       " 0.34230610728263855,\n",
       " 0.34227895736694336,\n",
       " 0.34209585189819336,\n",
       " 0.3426952660083771,\n",
       " 0.342147558927536,\n",
       " 0.34170711040496826,\n",
       " 0.3424224555492401,\n",
       " 0.3421942889690399,\n",
       " 0.3421476185321808,\n",
       " 0.3422015607357025,\n",
       " 0.34187746047973633,\n",
       " 0.34180504083633423,\n",
       " 0.3417101502418518,\n",
       " 0.3421693444252014,\n",
       " 0.3413205146789551,\n",
       " 0.3413635492324829,\n",
       " 0.3411341905593872,\n",
       " 0.34089308977127075,\n",
       " 0.34138667583465576,\n",
       " 0.3415903151035309,\n",
       " 0.3414650559425354,\n",
       " 0.3410617411136627,\n",
       " 0.34127914905548096,\n",
       " 0.34118059277534485,\n",
       " 0.3411083519458771,\n",
       " 0.3409709334373474,\n",
       " 0.3411938548088074,\n",
       " 0.3416078984737396,\n",
       " 0.3412914574146271,\n",
       " 0.34071847796440125,\n",
       " 0.3409903645515442,\n",
       " 0.3411673307418823,\n",
       " 0.34095683693885803,\n",
       " 0.34092819690704346,\n",
       " 0.3415430188179016,\n",
       " 0.3410102128982544,\n",
       " 0.3408155143260956,\n",
       " 0.34044739603996277,\n",
       " 0.3408734202384949,\n",
       " 0.34075915813446045,\n",
       " 0.3407555818557739,\n",
       " 0.34110671281814575,\n",
       " 0.3399077355861664,\n",
       " 0.3405205011367798,\n",
       " 0.3401731252670288,\n",
       " 0.34091007709503174,\n",
       " 0.3401150405406952,\n",
       " 0.340660035610199,\n",
       " 0.34042683243751526,\n",
       " 0.34041833877563477,\n",
       " 0.3401542007923126,\n",
       " 0.34017232060432434,\n",
       " 0.339929461479187,\n",
       " 0.340302973985672,\n",
       " 0.33969739079475403,\n",
       " 0.3397725820541382,\n",
       " 0.34061703085899353,\n",
       " 0.3399021327495575,\n",
       " 0.3397987484931946,\n",
       " 0.34019041061401367,\n",
       " 0.3400711119174957,\n",
       " 0.3399018347263336,\n",
       " 0.33962446451187134,\n",
       " 0.33987006545066833,\n",
       " 0.34001827239990234,\n",
       " 0.339608371257782,\n",
       " 0.34007740020751953,\n",
       " 0.34034329652786255,\n",
       " 0.33968260884284973,\n",
       " 0.3398117423057556,\n",
       " 0.3402732014656067,\n",
       " 0.3395635783672333,\n",
       " 0.3394532799720764,\n",
       " 0.33975157141685486,\n",
       " 0.3393895626068115,\n",
       " 0.33872190117836,\n",
       " 0.3393386900424957,\n",
       " 0.339417427778244,\n",
       " 0.339540958404541,\n",
       " 0.3398156762123108,\n",
       " 0.3392419219017029,\n",
       " 0.33897581696510315,\n",
       " 0.3395894169807434,\n",
       " 0.33863502740859985,\n",
       " 0.33881253004074097,\n",
       " 0.3389519155025482,\n",
       " 0.3398873507976532,\n",
       " 0.3383808135986328,\n",
       " 0.33852100372314453,\n",
       " 0.339124470949173,\n",
       " 0.3387575149536133,\n",
       " 0.3396706283092499,\n",
       " 0.3388635218143463,\n",
       " 0.3381897509098053,\n",
       " 0.3383679687976837,\n",
       " 0.3390992283821106,\n",
       " 0.33946672081947327,\n",
       " 0.3390015959739685,\n",
       " 0.33906155824661255,\n",
       " 0.33801209926605225,\n",
       " 0.33872175216674805,\n",
       " 0.3383333086967468,\n",
       " 0.33865272998809814,\n",
       " 0.3385676145553589,\n",
       " 0.3385618031024933,\n",
       " 0.3386450707912445,\n",
       " 0.3384495973587036,\n",
       " 0.3385785222053528,\n",
       " 0.3393336534500122,\n",
       " 0.33862727880477905,\n",
       " 0.33838513493537903,\n",
       " 0.3385982811450958,\n",
       " 0.33864712715148926,\n",
       " 0.33850347995758057,\n",
       " 0.3383433520793915,\n",
       " 0.3383581340312958,\n",
       " 0.33909013867378235,\n",
       " 0.33865267038345337,\n",
       " 0.33863627910614014,\n",
       " 0.3379686772823334,\n",
       " 0.33922526240348816,\n",
       " 0.33830469846725464,\n",
       " 0.3376021385192871,\n",
       " 0.3385072350502014,\n",
       " 0.3381572663784027,\n",
       " 0.33767828345298767,\n",
       " 0.3382231593132019,\n",
       " 0.33846914768218994,\n",
       " 0.33803799748420715,\n",
       " 0.33818092942237854,\n",
       " 0.33846402168273926,\n",
       " 0.33890506625175476,\n",
       " 0.3385748267173767,\n",
       " 0.3375188410282135,\n",
       " 0.3384254574775696,\n",
       " 0.33756232261657715,\n",
       " 0.3382534682750702,\n",
       " 0.33779144287109375,\n",
       " 0.33777618408203125,\n",
       " 0.33754637837409973,\n",
       " 0.3377627730369568,\n",
       " 0.3382136821746826,\n",
       " 0.3388215899467468,\n",
       " 0.3383996784687042,\n",
       " 0.3381040394306183,\n",
       " 0.33792561292648315,\n",
       " 0.3377944529056549,\n",
       " 0.33788803219795227,\n",
       " 0.3376089632511139,\n",
       " 0.337638795375824,\n",
       " 0.33761513233184814,\n",
       " 0.33800891041755676,\n",
       " 0.3380158543586731,\n",
       " 0.33724477887153625,\n",
       " 0.33726945519447327,\n",
       " 0.33790358901023865,\n",
       " 0.3374362289905548,\n",
       " 0.33817875385284424,\n",
       " 0.33733460307121277,\n",
       " 0.33861520886421204,\n",
       " 0.33720359206199646,\n",
       " 0.33729374408721924,\n",
       " 0.3380174934864044,\n",
       " 0.3371274769306183,\n",
       " 0.3379758298397064,\n",
       " 0.33689790964126587,\n",
       " 0.33799418807029724,\n",
       " 0.33733490109443665,\n",
       " 0.3370338976383209,\n",
       " 0.33736440539360046,\n",
       " 0.3376038074493408,\n",
       " 0.337940514087677,\n",
       " 0.3373728096485138,\n",
       " 0.33700767159461975,\n",
       " 0.3373218774795532,\n",
       " 0.3375101089477539,\n",
       " 0.3387071490287781,\n",
       " 0.33717626333236694,\n",
       " 0.3376829922199249,\n",
       " 0.33746203780174255,\n",
       " 0.33751407265663147,\n",
       " 0.3371928632259369,\n",
       " 0.33672985434532166,\n",
       " 0.33694860339164734,\n",
       " 0.3375670611858368,\n",
       " 0.3372557759284973,\n",
       " 0.33649125695228577,\n",
       " 0.3372107148170471,\n",
       " 0.3375547230243683,\n",
       " 0.33625373244285583,\n",
       " 0.33764296770095825,\n",
       " 0.33672311902046204,\n",
       " 0.3374612033367157,\n",
       " 0.33738747239112854,\n",
       " 0.33683037757873535,\n",
       " 0.33733218908309937,\n",
       " 0.3372255563735962,\n",
       " 0.33743274211883545,\n",
       " 0.33751001954078674,\n",
       " 0.3363848924636841,\n",
       " 0.3371177315711975,\n",
       " 0.3369005620479584,\n",
       " 0.3368953466415405,\n",
       " 0.3374845087528229,\n",
       " 0.33685532212257385,\n",
       " 0.33767402172088623,\n",
       " 0.33687010407447815,\n",
       " 0.33739227056503296,\n",
       " 0.3367815911769867,\n",
       " 0.3368232548236847,\n",
       " 0.3364965319633484,\n",
       " 0.3370777666568756,\n",
       " 0.3369569778442383,\n",
       " 0.3365875482559204,\n",
       " 0.3370065987110138,\n",
       " 0.3371204435825348,\n",
       " 0.33744168281555176,\n",
       " 0.3368685841560364,\n",
       " 0.3368695378303528,\n",
       " 0.3363642692565918,\n",
       " 0.33648329973220825,\n",
       " 0.33744925260543823,\n",
       " 0.3363654613494873,\n",
       " 0.33613574504852295,\n",
       " 0.33663633465766907,\n",
       " 0.33681783080101013,\n",
       " 0.337003231048584,\n",
       " 0.3371046781539917,\n",
       " 0.33629274368286133,\n",
       " 0.3368092477321625,\n",
       " 0.3382128179073334,\n",
       " 0.33670350909233093,\n",
       " 0.33770981431007385,\n",
       " 0.33698776364326477,\n",
       " 0.33738234639167786,\n",
       " 0.33665114641189575,\n",
       " 0.33621132373809814,\n",
       " 0.33656400442123413,\n",
       " 0.33640533685684204,\n",
       " 0.3360309600830078,\n",
       " 0.3368404507637024,\n",
       " 0.336325079202652,\n",
       " 0.33662885427474976,\n",
       " 0.3367741107940674,\n",
       " 0.33690646290779114,\n",
       " 0.33603301644325256,\n",
       " 0.336730420589447,\n",
       " 0.3373745083808899,\n",
       " 0.3358304500579834,\n",
       " 0.3371509313583374,\n",
       " 0.3366357684135437,\n",
       " 0.33634495735168457,\n",
       " 0.3369598984718323,\n",
       " 0.33689501881599426,\n",
       " 0.3360307514667511,\n",
       " 0.3363654315471649,\n",
       " 0.33733877539634705,\n",
       " 0.3359210193157196,\n",
       " 0.33655521273612976,\n",
       " 0.3368714153766632,\n",
       " 0.3365764021873474,\n",
       " 0.33653491735458374,\n",
       " 0.33625128865242004,\n",
       " 0.3362214267253876,\n",
       " 0.33571723103523254,\n",
       " 0.33663293719291687,\n",
       " 0.33621862530708313,\n",
       " 0.3361368775367737,\n",
       " 0.33618196845054626,\n",
       " 0.336366206407547,\n",
       " 0.335833340883255,\n",
       " 0.336125910282135,\n",
       " 0.33622461557388306,\n",
       " 0.3367525339126587,\n",
       " 0.33577874302864075,\n",
       " 0.3360787034034729,\n",
       " 0.33593255281448364,\n",
       " 0.33782073855400085,\n",
       " 0.33580467104911804,\n",
       " 0.3358924090862274,\n",
       " 0.3359106481075287,\n",
       " 0.33580687642097473,\n",
       " 0.3363415002822876,\n",
       " 0.33628368377685547,\n",
       " 0.3355945348739624,\n",
       " 0.33638444542884827,\n",
       " 0.33613622188568115,\n",
       " 0.3364368975162506,\n",
       " 0.3353720009326935,\n",
       " 0.3363931179046631,\n",
       " 0.33598724007606506,\n",
       " 0.3361765444278717,\n",
       " 0.3356628119945526,\n",
       " 0.33564481139183044,\n",
       " 0.33589208126068115,\n",
       " 0.33597636222839355,\n",
       " 0.3361961543560028,\n",
       " 0.33571887016296387,\n",
       " 0.33616989850997925,\n",
       " 0.33631935715675354,\n",
       " 0.3365445137023926,\n",
       " 0.3356676697731018,\n",
       " 0.33610206842422485,\n",
       " 0.3360268771648407,\n",
       " 0.33649739623069763,\n",
       " 0.3357555866241455,\n",
       " 0.33565986156463623,\n",
       " 0.3361338973045349,\n",
       " 0.3365838825702667,\n",
       " 0.33556586503982544,\n",
       " 0.3354998230934143,\n",
       " 0.3357252776622772,\n",
       " 0.33515700697898865,\n",
       " 0.3371519446372986,\n",
       " 0.3354424834251404,\n",
       " 0.33533692359924316,\n",
       " 0.3359176218509674,\n",
       " 0.33557185530662537,\n",
       " 0.3371428847312927,\n",
       " 0.33568713068962097,\n",
       " 0.33546966314315796,\n",
       " 0.33647722005844116,\n",
       " 0.3360576331615448,\n",
       " 0.335218608379364,\n",
       " 0.3373558819293976,\n",
       " 0.3354065418243408,\n",
       " 0.3355168104171753,\n",
       " 0.33532702922821045,\n",
       " 0.3357902765274048,\n",
       " 0.3359375596046448,\n",
       " 0.33553749322891235,\n",
       " 0.33561620116233826,\n",
       " 0.3359523415565491,\n",
       " 0.3357773423194885,\n",
       " 0.33525288105010986,\n",
       " 0.3369123637676239,\n",
       " 0.33514508605003357,\n",
       " 0.3359060287475586,\n",
       " 0.3353996276855469,\n",
       " 0.3357902467250824,\n",
       " 0.33556225895881653,\n",
       " 0.335299015045166,\n",
       " 0.3351191282272339,\n",
       " 0.334729939699173,\n",
       " 0.33512553572654724,\n",
       " 0.33540821075439453,\n",
       " 0.33609965443611145,\n",
       " 0.3353293538093567,\n",
       " 0.3352435529232025,\n",
       " 0.3356194496154785,\n",
       " 0.3354414999485016,\n",
       " 0.33507630228996277,\n",
       " 0.3356478214263916,\n",
       " 0.33541199564933777,\n",
       " 0.33517587184906006,\n",
       " 0.3351413607597351,\n",
       " 0.33532804250717163,\n",
       " 0.33649879693984985,\n",
       " 0.3356223702430725,\n",
       " 0.3388853371143341,\n",
       " 0.3376045823097229,\n",
       " 0.3365802764892578,\n",
       " 0.33717289566993713,\n",
       " 0.33585482835769653,\n",
       " 0.3355388641357422,\n",
       " 0.3356475830078125,\n",
       " 0.3360707461833954,\n",
       " 0.3352559506893158,\n",
       " 0.335669606924057,\n",
       " 0.33536115288734436,\n",
       " 0.33523640036582947,\n",
       " 0.3348589837551117,\n",
       " 0.336031973361969,\n",
       " 0.3347994387149811,\n",
       " 0.3360034227371216,\n",
       " 0.33463260531425476,\n",
       " 0.33495160937309265,\n",
       " 0.3355199992656708,\n",
       " 0.3356923460960388,\n",
       " 0.33524662256240845,\n",
       " 0.33471155166625977,\n",
       " 0.33553481101989746,\n",
       " 0.33538350462913513,\n",
       " 0.3347272574901581,\n",
       " 0.33531686663627625,\n",
       " 0.3353118598461151,\n",
       " 0.3349841833114624,\n",
       " 0.33504852652549744,\n",
       " 0.3352312445640564,\n",
       " 0.33627480268478394,\n",
       " 0.3350811302661896,\n",
       " 0.3356685936450958,\n",
       " 0.33520326018333435,\n",
       " 0.33467233180999756,\n",
       " 0.3351314961910248,\n",
       " 0.3349149823188782,\n",
       " 0.3354981541633606,\n",
       " 0.3348458409309387,\n",
       " 0.3353198766708374,\n",
       " 0.33543962240219116,\n",
       " 0.33483216166496277,\n",
       " 0.3357340097427368,\n",
       " 0.33518823981285095,\n",
       " 0.33480149507522583,\n",
       " 0.33564651012420654,\n",
       " 0.3345690369606018,\n",
       " 0.33524855971336365,\n",
       " 0.33519288897514343,\n",
       " 0.33568939566612244,\n",
       " 0.3358914256095886,\n",
       " 0.33514484763145447,\n",
       " 0.33441293239593506,\n",
       " 0.33440306782722473,\n",
       " 0.3349882960319519,\n",
       " 0.3345639109611511,\n",
       " 0.3353317379951477,\n",
       " 0.3345126509666443,\n",
       " 0.3356435298919678,\n",
       " 0.3346286118030548,\n",
       " 0.33461201190948486,\n",
       " 0.334840327501297,\n",
       " 0.33444440364837646,\n",
       " 0.3348552882671356,\n",
       " 0.33447444438934326,\n",
       " 0.33483266830444336,\n",
       " 0.3346497714519501,\n",
       " 0.3346925675868988,\n",
       " 0.334365576505661,\n",
       " 0.3347286880016327,\n",
       " 0.33499836921691895,\n",
       " 0.3356517553329468,\n",
       " 0.334872305393219,\n",
       " 0.33497411012649536,\n",
       " 0.3345852792263031,\n",
       " 0.335713654756546,\n",
       " 0.3344455361366272,\n",
       " 0.3352736532688141,\n",
       " 0.33491358160972595,\n",
       " 0.33423104882240295,\n",
       " 0.33480578660964966,\n",
       " 0.3343413174152374,\n",
       " 0.33431708812713623,\n",
       " 0.3347853720188141,\n",
       " 0.3343852460384369,\n",
       " 0.3358765244483948,\n",
       " 0.3344728350639343,\n",
       " 0.33416733145713806,\n",
       " 0.33499541878700256,\n",
       " 0.3348771035671234,\n",
       " 0.3343387246131897,\n",
       " 0.3343088626861572,\n",
       " 0.33404260873794556,\n",
       " 0.3354865610599518,\n",
       " 0.33466094732284546,\n",
       " 0.33447617292404175,\n",
       " 0.3344215750694275,\n",
       " 0.3350207209587097,\n",
       " 0.3343488574028015,\n",
       " 0.3342573344707489,\n",
       " 0.33432063460350037,\n",
       " 0.33496955037117004,\n",
       " 0.3350394666194916,\n",
       " 0.33440548181533813,\n",
       " 0.33510109782218933,\n",
       " 0.3344655930995941,\n",
       " 0.33434227108955383,\n",
       " 0.33399781584739685,\n",
       " 0.3346344828605652,\n",
       " 0.335092157125473,\n",
       " 0.3344372808933258,\n",
       " 0.3347366452217102,\n",
       " 0.3340455889701843,\n",
       " 0.33477750420570374,\n",
       " 0.3340522348880768,\n",
       " 0.33483490347862244,\n",
       " 0.3358790874481201,\n",
       " 0.33506208658218384,\n",
       " 0.3345104455947876,\n",
       " 0.33396270871162415,\n",
       " 0.33523932099342346,\n",
       " 0.33454248309135437,\n",
       " 0.3349648416042328,\n",
       " 0.3342999517917633,\n",
       " 0.33536049723625183,\n",
       " 0.3348688781261444,\n",
       " 0.3345487117767334,\n",
       " 0.33422625064849854,\n",
       " 0.33444079756736755,\n",
       " 0.33404430747032166,\n",
       " 0.3346099555492401,\n",
       " 0.3339509069919586,\n",
       " 0.33363014459609985,\n",
       " 0.3346611261367798,\n",
       " 0.334736168384552,\n",
       " 0.3345097601413727,\n",
       " 0.3346472382545471,\n",
       " 0.33462071418762207,\n",
       " 0.3341025114059448,\n",
       " 0.3338703215122223,\n",
       " 0.3341143727302551,\n",
       " 0.3349466323852539,\n",
       " 0.3347347676753998,\n",
       " 0.3350052237510681,\n",
       " 0.33354631066322327,\n",
       " 0.3339015245437622,\n",
       " 0.334316223859787,\n",
       " 0.33430513739585876,\n",
       " 0.33409467339515686,\n",
       " 0.3345569372177124,\n",
       " 0.3341178596019745,\n",
       " 0.3335329592227936,\n",
       " 0.33445221185684204,\n",
       " 0.3344493806362152,\n",
       " 0.3340092599391937,\n",
       " 0.3334507644176483,\n",
       " 0.3364221453666687,\n",
       " 0.33382976055145264,\n",
       " 0.3339017331600189,\n",
       " 0.33424505591392517,\n",
       " 0.33400389552116394]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b390be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 6,  ..., 5, 6, 6], device='cuda:0')\n",
      "correct _rate: 144160/167077 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    model2.eval()\n",
    "    train_x, train_y = Variable(train_X), Variable(train_Y)\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    output = model2(train_x)\n",
    "    pred = torch.max(output.data, 1)[1]\n",
    "    print(pred)\n",
    "    correct += pred.eq(train_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(train_y)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f1e99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.tensor(twoS_test_data.values, dtype=torch.float32)\n",
    "test_Y = torch.tensor(attack_test.values, dtype=torch.long) \n",
    "\n",
    "test = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8329e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct _rate: 61129/71605 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model2.eval()\n",
    "    correct = 0\n",
    "    pred_list = list()\n",
    "    test_y_list = list()\n",
    "    for test_x, test_y in test_loader:\n",
    "        test_x, test_y = Variable(test_x), Variable(test_y)\n",
    "        test_y_list.extend(test_y.to('cpu').detach().numpy().tolist())\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        output = model2(test_x)\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        pred_list.extend(pred.to('cpu').detach().numpy().tolist())\n",
    "        correct += pred.eq(test_y.data.view_as(pred)).sum() \n",
    "    # correct_rate\n",
    "    data_num = len(test_loader.dataset)\n",
    "    print('correct _rate: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8edd80a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8536973675022694"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e555e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103748849882404"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "faf4316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49604555642732606"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6abfbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114422263239946"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y_list, pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5700540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   58     0     0   454     1     0    90     0    10     0]\n",
      " [    0    42     7   455     0     0     5     4     7     0]\n",
      " [    0     4   146  3333    26     7    56    11    65     0]\n",
      " [    6    11    54  9321   112    14   289   112    87     3]\n",
      " [    1     3     6   598  2551     6  2176    23    37     0]\n",
      " [    0     3    31   193     7 11807    13     2     7     1]\n",
      " [    5     0     3   152   752     3 34816    19    28     0]\n",
      " [    0     2    35   773    86     1    94  2177    11     0]\n",
      " [    0     6     3    57    31     2    28    17   206     0]\n",
      " [    0     0     0    35     1     0     2     0     0     5]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_y_list, pred_list, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "445269f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "159c367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75670d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9342997540056381"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96e286cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(twoS_test_data, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac6330c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528594371901403"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_test_data, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70498b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9342997540056381"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(twoS_train_data, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7f15b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493680608896027"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_train_norm, attack_train)\n",
    "clf.score(testdata_norm, attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "317d1ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338927560346427"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(data_train_norm, attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c92cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51f53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5e491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6794f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
